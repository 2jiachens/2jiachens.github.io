<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="NAS-PINN: Neural architecture search-guided physics-informed neural network for solving PDEs(NAS-PINN：神经网络结构搜索引导的物理信息神经网络，用于求解偏微分方程) 摘要 物理信息神经网络( PINN )自提出以来一直是求解偏微分方程的主流框架。通过损失函数将物理信息融入到神经网络中，它">
<meta property="og:type" content="article">
<meta property="og:title" content="NAS-PINN">
<meta property="og:url" content="http://example.com/2025/02/11/NAS-PINN/index.html">
<meta property="og:site_name" content="我的博客">
<meta property="og:description" content="NAS-PINN: Neural architecture search-guided physics-informed neural network for solving PDEs(NAS-PINN：神经网络结构搜索引导的物理信息神经网络，用于求解偏微分方程) 摘要 物理信息神经网络( PINN )自提出以来一直是求解偏微分方程的主流框架。通过损失函数将物理信息融入到神经网络中，它">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2025/02/11/NAS-PINN/1.jpg">
<meta property="og:image" content="http://example.com/2025/02/11/NAS-PINN/2.jpg">
<meta property="og:image" content="http://example.com/2025/02/11/NAS-PINN/3.jpg">
<meta property="og:image" content="http://example.com/2025/02/11/NAS-PINN/4.jpg">
<meta property="og:image" content="http://example.com/2025/02/11/NAS-PINN/5.jpg">
<meta property="og:image" content="http://example.com/2025/02/11/NAS-PINN/6.jpg">
<meta property="og:image" content="http://example.com/2025/02/11/NAS-PINN/7.jpg">
<meta property="og:image" content="http://example.com/2025/02/11/NAS-PINN/8.jpg">
<meta property="article:published_time" content="2025-02-11T01:43:32.000Z">
<meta property="article:modified_time" content="2025-02-11T03:45:56.995Z">
<meta property="article:author" content="宋嘉晨">
<meta property="article:tag" content="神经网络架构">
<meta property="article:tag" content="PINN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2025/02/11/NAS-PINN/1.jpg">

<link rel="canonical" href="http://example.com/2025/02/11/NAS-PINN/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>NAS-PINN | 我的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">我的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-guestbook">

    <a href="/guestbook/" rel="section"><i class="fa fa-book fa-fw"></i>留言板</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/02/11/NAS-PINN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="宋嘉晨">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          NAS-PINN
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-02-11 09:43:32 / 修改时间：11:45:56" itemprop="dateCreated datePublished" datetime="2025-02-11T09:43:32+08:00">2025-02-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E6%B3%9B%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文泛读</span></a>
                </span>
            </span>

          
            <span id="/2025/02/11/NAS-PINN/" class="post-meta-item leancloud_visitors" data-flag-title="NAS-PINN" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2025/02/11/NAS-PINN/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/02/11/NAS-PINN/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.9k</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="nas-pinn-neural-architecture-search-guided-physics-informed-neural-network-for-solving-pdesnas-pinn神经网络结构搜索引导的物理信息神经网络用于求解偏微分方程">NAS-PINN:
Neural architecture search-guided physics-informed neural network for
solving
PDEs(NAS-PINN：神经网络结构搜索引导的物理信息神经网络，用于求解偏微分方程)</h1>
<h2 id="摘要">摘要</h2>
<p>物理信息神经网络( PINN
)自提出以来一直是求解偏微分方程的主流框架。通过损失函数将物理信息融入到神经网络中，它可以以无监督的方式预测PDEs的解。然而，神经网络结构的设计基本依赖于先验知识和经验，这造成了很大的麻烦和较高的计算开销。因此，<strong>我们提出了一种神经结构搜索引导的方法，即NAS
- PINN，用于自动搜索求解某些PDEs的最佳神经结构</strong>。
通过将搜索空间松弛为连续空间，并利用掩码实现不同形状张量的添加，NAS -
PINN可以通过双层优化进行训练，其中内层循环优化神经网络的权重和偏置，外层循环优化网络结构参数。我们通过包括Poisson，Burgers和Advection方程在内的几个数值实验来验证NAS
-
PINN的能力。总结了求解不同PDE的有效神经网络结构的特点，可用于指导PINN中神经网络的设计。研究发现，更多的隐藏层并不一定意味着更好的性能，有时可能是有害的。
特别是对于Poisson和Advection，在PINNs中更适合采用神经元数目较多的浅层神经网络。研究还表明，对于复杂问题，具有残差连接的神经网络可以提高PINNs的性能。
<span id="more"></span></p>
<h2 id="介绍">介绍</h2>
<p>神经网络结构搜索( Neural Architecture Search，NAS
)是一种在特定搜索空间中搜索最优神经网络结构的算法。传统的NAS算法通过神经网络模块的排列组合来构建架构，并对这些架构进行训练和测试以确定其性能，然后根据性能排序选择最佳的神经网络架构。这样的离散过程面临着计算效率低和计算成本高的问题。因此，减少计算开销、提高搜索效率一直是NAS的主要研究热点之一。
<strong>本文将NAS融入PINN的框架中，提出了一种神经架构搜索引导的物理信息神经网络(
NAS-PINN)</strong>。我们实现了用少量数据自动搜索求解给定PDE的最佳神经网络结构。掩码用于张量的添加，以帮助搜索每层中不同数量的神经元。通过对一系列PDE的数值实验，验证了所提方法的有效性.通过对数值结果的分析，总结了高效神经网络结构的特点，为PINNs的进一步研究提供了指导。</p>
<h2 id="方法">方法</h2>
<h3 id="pinn的框架">PINN的框架</h3>
<p><img src="/2025/02/11/NAS-PINN/1.jpg"></p>
<h3 id="可微nas">可微NAS</h3>
<p>在传统的NAS算法中，神经网络的层数通常是固定的，并为每一层提供特定的操作选择。这样的配置使得搜索空间不连续，无法通过基于梯度的方法进行优化，极大地限制了算法的收敛速度和效率。
Liu等人[ 29 ]提出了DARTS，并引入了可微NAS的概念。设<span class="math inline">\(O\)</span>是一个由候选操作组成的集合，其中任何一个操作都表示关于输入x的某个函数<span class="math inline">\(o(x)\)</span>.通过对候选操作施加松弛，可以使搜索空间连续：
<span class="math display">\[
\bar{o}^{(i,j)}(x)=\sum_{o\in
O}\frac{exp(\alpha^{(i,j)}_o)}{\textstyle\sum_{o&#39;\in
O}exp(\alpha^{(i,j)_{o&#39;}})}o(x) \qquad (6)
\]</span> 其中<span class="math inline">\(\bar
o^{(i,j)}(x)\)</span>为松弛后第<span class="math inline">\(i\)</span>层与第<span class="math inline">\(j\)</span>层之间的混合运算，<span class="math inline">\(\alpha^{(i,j)}_o\)</span>为运算<span class="math inline">\(o\)</span>的权.现在测试和比较所有可能的操作组合的离散过程可以简化为通过基于梯度的优化方法学习一组合适的权重<span class="math inline">\(\alpha^{(i,j)}_o\)</span>。当算法收敛时，通过选择权重最高的候选操作，可以将松弛的搜索空间提取到离散的神经架构中。</p>
<h3 id="掩码">掩码</h3>
<p>虽然式(6)将搜索空间缩小为一个连续的空间，张量运算只允许相同形状的张量相加，使得搜索神经元个数不切实际，如图2(a)所示。受卷积神经网络中零填充的启发，我们可以将神经元填充到最大数量k，如图2
(b)所示。在图2(c)中，通过将填充的神经元乘以一个零张量掩码，我们将额外的神经元去激活，以模拟不同数量的神经元。最后，通过共享权重，可以将可选的隐藏层减少为一个，输出y可以表示为：
<span class="math display">\[
\mathbf{y} = \sigma(\mathbf{w}\cdot\mathbf{x}+\mathbf{b})\cdot
\begin{pmatrix}
[g_1,g_2,g_3]\times     
\begin{bmatrix}
   \mathbf{mask}_1 \\
   \mathbf{mask}_2 \\
   \mathbf{mask}_3
\end{bmatrix}^T
\end{pmatrix}
\]</span> 其中<span class="math inline">\(\sigma(\cdot)\)</span>为激活函数，<span class="math inline">\(\mathbf{w}\)</span>和<span class="math inline">\(\mathbf{b}\)</span>分别为单隐层的权值和偏置，<span class="math inline">\(g_i\)</span>为标量，为每个神经元个数的权值，<span class="math inline">\(\mathbf{mask}_i\)</span>为每个神经元个数的掩码，形状为<span class="math inline">\(1\times k\)</span>。假设神经元个数为<span class="math inline">\(j\)</span>，则<span class="math inline">\(\mathbf{mask}\)</span>的前<span class="math inline">\(j\)</span>个元素为1，其余<span class="math inline">\((k-j)\)</span>个元素为0。 <img src="/2025/02/11/NAS-PINN/2.jpg" alt="fig.2">
为了确定层数，我们引入身份变换作为操作，即跳过该层，且输出<span class="math inline">\(\mathbf{y}\)</span>变为: <span class="math display">\[
\mathbf{y} = \alpha_1 \cdot
\mathbf{x}+\alpha_2\cdot\sigma(\mathbf{w}\cdot\mathbf{x}+\mathbf{b})\cdot
\begin{pmatrix}
[g_1,g_2,g_3]\times     
\begin{bmatrix}
   \mathbf{mask}_1 \\
   \mathbf{mask}_2 \\
   \mathbf{mask}_3
\end{bmatrix}^T
\end{pmatrix} \qquad (8)
\]</span> 其中，<span class="math inline">\(\alpha_1\)</span>为身份转换权重，表示跳过该层，<span class="math inline">\(\alpha_2\)</span>为保留该层的权重。
式(8)给出了每层输入和输出之间的映射关系，通过反复应用，可以建立一个DNN模型，其中最合适的层可以根据权重<span class="math inline">\(\alpha\)</span>来选择，最合适的每层神经元可以根据权重<span class="math inline">\(g\)</span>来决定。这里，我们将<span class="math inline">\(\alpha\)</span>和<span class="math inline">\(g\)</span>统称为<span class="math inline">\(\boldsymbol{\alpha}\)</span>，<span class="math inline">\(\bf{w}\)</span>和<span class="math inline">\(\bf{b}\)</span>统称为<span class="math inline">\(\boldsymbol{\theta}\)</span>。</p>
<h3 id="mas-pinn">MAS-PINN</h3>
<p>现在我们可以得到NAS -
PINN的整体框架，如图3所示，它可以被认为是一个<strong>双层优化问题</strong>。在内循环中，对DNN的权值和偏置<span class="math inline">\(\boldsymbol{\theta}\)</span>进行优化，而在外循环中，优化目标是寻找最佳的<span class="math inline">\(\boldsymbol{\alpha}\)</span>。其过程可以表示为：
<span class="math display">\[
\underset{\boldsymbol{\alpha}}{min}MSE(\boldsymbol{\theta}^*,\boldsymbol{\alpha})
\\ s.t. \boldsymbol{\theta}^*=
\underset{\boldsymbol{\theta}}{argmin}Loss(\boldsymbol{\theta},\boldsymbol{\alpha})
\]</span> 内环的损失函数可以设计为式( 2 ) ~ ( 5
)（PINN损失函数：数据匹配损失，PDE残差损失，边界条件损失）和外环的损失函数可以写成：
<span class="math display">\[
MSE=\frac{1}{n}\sum^n_{i=1}(\hat u-u)^2  \qquad(10)
\]</span>
其中u是已知的解析解或数值解，n是数据点的个数，对于外循环，所需的n可以很小。这样的双层优化问题可以通过交替优化来解决，相应的过程在算法1中展示。
当训练结束时，可以根据<span class="math inline">\(\boldsymbol{\alpha}\)</span>推导出离散的神经网络模型。基本上，我们可以首先通过比较<span class="math inline">\(a_1\)</span>和<span class="math inline">\(a_2\)</span>来决定是否跳过某一层。如果保留该层，我们可以根据<span class="math inline">\(g\)</span>来决定神经元的数量。如果跳过某一层，则无需考察其权重<span class="math inline">\(g\)</span>。 在一些<span class="math inline">\(a_1\)</span>和<span class="math inline">\(a_2\)</span>相对接近的情况下，我们假设跳过层和保留层同样重要，并给出了一个混合模型。在混合模型中，层是身份变换和神经网络操作的组合。神经元的数量决定于一个离散的神经元，因此这些层可以表示为：
<span class="math display">\[
\mathbf{y} = \alpha_1 \cdot
\mathbf{x}+\alpha_2\cdot\sigma(\mathbf{w}\cdot\mathbf{x}+\mathbf{b})\cdot
(g_{max}\times \boldsymbol{mask}_{max})^T
\]</span> 式中,<span class="math inline">\(g_{max}\)</span>为所有权值<span class="math inline">\(g\)</span>中的最大值，<span class="math inline">\(\boldsymbol{mask}_{max}\)</span>为对应于<span class="math inline">\(g_{max}\)</span>的零张量掩码。 <img src="/2025/02/11/NAS-PINN/3.jpg" alt="fig.3"> <img src="/2025/02/11/NAS-PINN/4.jpg" alt="algorithm 1"></p>
<h2 id="实验">实验</h2>
<h3 id="possion-equation">Possion equation</h3>
<p>泊松方程是一类描述电磁场和热场的基本偏微分方程，在电磁学和机械工程中有着广泛的应用。这里，我们考虑一个带有Dirichlet边界条件的二维Poisson方程：
<img src="/2025/02/11/NAS-PINN/5.jpg" alt="possion equation"> 该方程有解析解：
<img src="/2025/02/11/NAS-PINN/6.jpg" alt="analytical solution">
我们首先考虑正方形计算域中的泊松方程，以验证所提出的NAS -
PINN的有效性。我们构造了一个相对较小的搜索空间，它是一个最多包含5个隐藏层的神经网络，每层包含30、50或70个神经元。对离散搜索空间中的每一种可能的神经架构分别进行训练和测试，作为网格搜索的近似实例。然后，我们使用NAS
-
PINN来搜索一个神经结构，并研究它是否是最好的。所有离散搜索空间中的363个架构由Adam训练，其中500个配置点在域内随机采样，100个边界点均匀分布在边界上。
在架构搜索阶段，1000个配置点和200个边界点采用与之前相同的策略进行采样，以搜索最佳的神经架构，并将Adam应用于架构搜索阶段。然后以与363架构相同的方式从头开始训练得到的神经架构。</p>
<p>为了进行更全面的比较，还对传统的Auto
ML方法SMAC进行了测试。SMAC是一个通用的用于超参数优化的贝叶斯优化包，对于所讨论的问题，需要优化的超参数是隐藏层的数量和神经元的数量。对于SMAC，一个相当小的研究空间包括15种不同的神经结构，其中每个隐藏层的神经元数量只能是相同的。SMAC使用与架构搜索阶段相同的1000个配置点和200个边界点。
最后，均匀采样1000000个点，测试所有收敛的神经架构。不同架构的预测解和误差分布如图4所示，L2误差如表1所示。所有实验均重复5次，L2误差由5次重复的平均值得到。
这些结构以序列的形式描述在表1中。序列的第一个和最后一个元素代表输入和输出通道，而其他元素代表每一层的神经元数目。例如，98号架构的输入大小为n×2，其中n为批次大小，2代表坐标x和y，第一层隐含层有70个神经元。通过NAS
- PINN得到的架构为No.358。</p>
<p>从表1和图4中，我们可以清楚地看到NAS-PINN的神经架构具有最小的L2误差和最小的最大误差值，并且其误差分布相比于其他架构也有所改善。因此，所提出的NASPINN确实可以在给定的搜索空间中找到最佳的神经网络结构。此外，虽然No.98也表现出相对较好的性能(在363种可能的体系结构中,它是第二好的体系结构)，但它比NAS-PINN的架构拥有更多的参数，这表明更多的参数并不一定意味着更好的性能，一个适当设计的神经架构显得尤为重要。
此外，在PINNs中，更深的神经网络总是更好的这一常识似乎并不是在所有情况下都是正确的。至少对于给定的泊松方程，浅层但宽的神经网络(隐含层较少,但每层神经元较多的神经网络)优于深层的神经网络。</p>
<p>与SMAC相比，NAS - PINN可以在更大、更灵活的搜索空间中进行搜索，从而NAS
-
PINN更有可能找到真正最佳的神经架构。值得注意的是，虽然SMAC在只有15个神经结构的较小搜索空间中进行搜索，但它需要SMAC
2。08 h找到357号架构，而NAS -
PINN使用1.57h，从363个不同的架构中找到358号架构。所有的数值实验均在Intel(R)Core
i9-9900 K @ 3.60 Ghz /NVIDIA GeForce Rtx 3090 上进行 <img src="/2025/02/11/NAS-PINN/7.jpg" alt="fig.4"> <img src="/2025/02/11/NAS-PINN/8.jpg" alt="table.1"></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/" rel="tag"># 神经网络架构</a>
              <a href="/tags/PINN/" rel="tag"># PINN</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/02/10/Lagrange%E5%AF%B9%E5%81%B6/" rel="prev" title="Lagrange对偶（Lagrange duality）">
      <i class="fa fa-chevron-left"></i> Lagrange对偶（Lagrange duality）
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/02/13/OPTIMAL-TRANSPORTATION-FOR-ELECTRICAL-IMPEDANCE-TOMOGRAPHY/" rel="next" title="OPTIMAL TRANSPORTATION FOR ELECTRICAL IMPEDANCE  TOMOGRAPHY">
      OPTIMAL TRANSPORTATION FOR ELECTRICAL IMPEDANCE  TOMOGRAPHY <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#nas-pinn-neural-architecture-search-guided-physics-informed-neural-network-for-solving-pdesnas-pinn%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%90%9C%E7%B4%A2%E5%BC%95%E5%AF%BC%E7%9A%84%E7%89%A9%E7%90%86%E4%BF%A1%E6%81%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%94%A8%E4%BA%8E%E6%B1%82%E8%A7%A3%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B"><span class="nav-text">NAS-PINN:
Neural architecture search-guided physics-informed neural network for
solving
PDEs(NAS-PINN：神经网络结构搜索引导的物理信息神经网络，用于求解偏微分方程)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D"><span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#pinn%E7%9A%84%E6%A1%86%E6%9E%B6"><span class="nav-text">PINN的框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%AF%E5%BE%AEnas"><span class="nav-text">可微NAS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8E%A9%E7%A0%81"><span class="nav-text">掩码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mas-pinn"><span class="nav-text">MAS-PINN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C"><span class="nav-text">实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#possion-equation"><span class="nav-text">Possion equation</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="宋嘉晨"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">宋嘉晨</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">宋嘉晨</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">50k</span>
</div>

<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共50k字</span>
  <span class="post-meta-divider">|</span>
  本站总访问量<span id="busuanzi_value_site_pv"></span>次
  <span class="post-meta-divider">|</span>
  本站访客数<span id="busuanzi_value_site_uv"></span>人次
  <span class="post-meta-divider">|</span>
  本文总阅读量<span id="busuanzi_value_page_pv"></span>次
</div>

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共50k字</span>
</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'x2HNNt4kVm1AzbK4G5OMYocX-gzGzoHsz',
      appKey     : 'UZukMakW4tBBED8F52h1Hgn4',
      placeholder: "输入你的评论\n不输入昵称则为匿名",
      avatar     : '',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/clicklove.js"></script>
