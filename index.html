<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="我的博客">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="我的博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="宋嘉晨">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>我的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">我的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-guestbook">

    <a href="/guestbook/" rel="section"><i class="fa fa-book fa-fw"></i>留言板</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/10/WGAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="宋嘉晨">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/10/WGAN/" class="post-title-link" itemprop="url">WGAN</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-10 09:20:32" itemprop="dateCreated datePublished" datetime="2025-03-10T09:20:32+08:00">2025-03-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-16 13:56:35" itemprop="dateModified" datetime="2025-03-16T13:56:35+08:00">2025-03-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文精读</span></a>
                </span>
            </span>

          
            <span id="/2025/03/10/WGAN/" class="post-meta-item leancloud_visitors" data-flag-title="WGAN" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2025/03/10/WGAN/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/03/10/WGAN/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>15k</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="wasserstein-gan">Wasserstein GAN</h1>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/10/WGAN/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/04/Numerical-Solution-of-Inverse-Problems-by-Weak-Adversarial-Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="宋嘉晨">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/04/Numerical-Solution-of-Inverse-Problems-by-Weak-Adversarial-Networks/" class="post-title-link" itemprop="url">Numerical Solution of Inverse Problems by Weak Adversarial  Networks</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-04 17:19:32" itemprop="dateCreated datePublished" datetime="2025-03-04T17:19:32+08:00">2025-03-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-16 10:48:22" itemprop="dateModified" datetime="2025-03-16T10:48:22+08:00">2025-03-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文精读</span></a>
                </span>
            </span>

          
            <span id="/2025/03/04/Numerical-Solution-of-Inverse-Problems-by-Weak-Adversarial-Networks/" class="post-meta-item leancloud_visitors" data-flag-title="Numerical Solution of Inverse Problems by Weak Adversarial  Networks" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2025/03/04/Numerical-Solution-of-Inverse-Problems-by-Weak-Adversarial-Networks/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/03/04/Numerical-Solution-of-Inverse-Problems-by-Weak-Adversarial-Networks/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>21k</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="numerical-solution-of-inverse-problems-by-weak-adversarial-networks弱对抗网络对反问题的数值求解">Numerical
Solution of Inverse Problems by Weak Adversarial
Networks（弱对抗网络对反问题的数值求解）</h1>
<p>期刊：Inverse Problems</p>
<p>时间：2020</p>
<h2 id="摘要">摘要</h2>
<p>本文发展了一种弱对抗网络方法来数值求解一类反问题，包括电阻抗层析成像和动态电阻抗层析成像问题。<strong>利用给定反问题的PDE的弱形式，其中解和测试函数被参数化为深度神经网络。然后，弱形式和边界条件诱导出一个关于网络参数的鞍点函数的极小极大问题</strong>。随着参数的交替更新，网络逐渐逼近反问题的解。对所提算法的收敛性给出了理论证明。
所提出的方法是完全无网格的，无需任何空间离散，特别适用于高维数和解的低正则性问题。对各种测试反问题的数值实验表明了该方法具有较高的精度和效率。</p>
<h2 id="介绍">介绍</h2>
<p>反问题(Inverse
Problems，IP)普遍存在于大量的科学学科中，包括地球物理[73]、信号处理与成像[9]、计算机视觉[61]、遥感与控制[87]、统计学[53]和机器学习[38]等。设<span class="math inline">\(\Omega\)</span>是<span class="math inline">\(\mathbb{R}^d\)</span>中的开集和有界集，则定义在<span class="math inline">\(\Omega\)</span>上的IP可表示为一般形式： <span class="math display">\[
\begin{aligned}
\mathcal{A}[u, \gamma]=0, &amp; &amp; \text { in } \Omega  \qquad(1a)\\
\mathcal{B}[u, \gamma]=0, &amp; &amp; \text { on } \partial \Omega
\qquad(1b)
\end{aligned}
\]</span> 其中<span class="math inline">\(\mathcal{A}[u,
\gamma]\)</span>指定一个微分方程，<strong><span class="math inline">\(u\)</span>是反介质问题中的解，<span class="math inline">\(\gamma\)</span>是反源问题中的源函数</strong>。方程<span class="math inline">\(\mathcal{A}\)</span>可以是常微分方程(ODE)，也可以是偏微分方程(PDE)，还可以是积分微分方程(IDE)，<span class="math inline">\((u, \gamma)\)</span>在区域<span class="math inline">\(\Omega\)</span>内需要满足(几乎)处处成立。边界值(以及如果适用的初始值)由<span class="math inline">\(\mathcal{B}[u, \gamma]\)</span>在<span class="math inline">\(\partial
\Omega\)</span>上给出。根据具体的应用，<span class="math inline">\(u\)</span>和/或<span class="math inline">\(\gamma\)</span>的部分信息可以在<span class="math inline">\(\Omega\)</span>的内部获得.那么IP
(1)就是找到同时满足(1a)和(1b)的<span class="math inline">\((u,
\gamma)\)</span>。</p>
<p>为了实例化我们的方法，我们主要以电阻抗成像(Electrical Impedance
Tomography，EIT)中经典的电导率逆问题[19、55]为例，介绍了本文的主要思想和推导过程。然而，我们的方法可以很容易地通过修改应用于其他类型的IP。一个动态EIT问题的例子将在第4节中给出。EIT的目标是根据电势<span class="math inline">\(u\)</span>，电流<span class="math inline">\(-\gamma \partial_{\vec{n}}
u\)</span>的测量和区域<span class="math inline">\(\Omega\)</span>的边界<span class="math inline">\(\partial \Omega\)</span>上/附近的<span class="math inline">\(\gamma\)</span> (也即<span class="math inline">\(\partial_{\vec{n}}
u\)</span>)的知识，确定定义在<span class="math inline">\(\Omega\)</span>上的未知介质的电导率分布<span class="math inline">\(\gamma(x)\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
-\nabla \cdot(\gamma \nabla u)-f=0, &amp; \text { in }
\Omega  \qquad(2a)\\
u-u_b=0, \gamma-\gamma_b=0, \partial_{\vec{n}} u-u_n=0, &amp; \text { on
} \partial \Omega \qquad(2b)
\end{aligned}
\]</span></p>
<p>其中<span class="math inline">\(u_b\)</span>为测量电压，<span class="math inline">\(\gamma_b\)</span>为物体表面附近的电导率，<span class="math inline">\(u_n \triangleq \nabla u \cdot \vec{n}\)</span>
，其中 <span class="math inline">\(\vec{n}\)</span>为<span class="math inline">\(\partial
\Omega\)</span>的外法线.值得注意的是，<strong>我们的方法并不像EIT问题[23、36、59]的经典方法那样估计与电导率函数相关的Dirichlet
- to - Neumann
(DtN)映射。相反，我们的目标是直接利用给定的数据数值求解一般的一类IPs(1)</strong>，以EIT问题(2)为原型例子，而不利用其特殊结构(例如,
DtN映射)。为了使我们的介绍简洁而有重点，我们只考虑(1a)中具有PDEs特征的<span class="math inline">\(\mathcal{A}[u,
\gamma]\)</span>的IP，并假设给定的IP是定义良好的且至少有一个(弱)解。</p>
<p>我们的方法是<strong>训练能够表示给定IP的解<span class="math inline">\((u,
\gamma)\)</span>的深度神经网络</strong>，与经典的数值方法相比有很大的改进，特别是对于高维问题。更具体地说，<strong>我们利用PDE
(1a)的弱形式，将IP转化为<span class="math inline">\(u\)</span>和<span class="math inline">\(\gamma\)</span>的算子范数最小化问题。然后将<span class="math inline">\(u\)</span>、未知系数<span class="math inline">\(\gamma\)</span>和测试函数<span class="math inline">\(\varphi\)</span>分别参数化为深度神经网络<span class="math inline">\(u_\theta, \gamma_\theta\)</span>, 和 <span class="math inline">\(\varphi_\eta\)</span>，网络参数为<span class="math inline">\((\theta, \eta)\)</span>，并形成参数为<span class="math inline">\((\theta,
\eta)\)</span>的鞍函数的极小极大问题。最后，我们应用随机梯度下降法交替更新网络参数，使得(<span class="math inline">\(u_\theta,
\gamma_\theta\)</span>)逐步逼近IP的解</strong>。利用深度神经网络对<span class="math inline">\((u,
\gamma)\)</span>进行参数化，不需要对空间域和时间域进行离散化，因此是完全无网格的。与经典的有限差分方法(FDM)和有限元法(FEM)相比，这是一种很有前途的替代方法，它们首先在[8]中使用了"维数灾难"这一术语。此外，<strong>我们的方法结合了弱解(原始网络)<span class="math inline">\((u, \gamma)\)</span>和测试函数(对抗网络) <span class="math inline">\(\varphi\)</span>的训练，由PDE的弱形式控制，这对解<span class="math inline">\((u,
\gamma)\)</span>的正则性要求较低，当解具有奇异性时，在许多实际应用中可能更有优势</strong>。</p>
<p>本论文的其余部分组织如下。我们首先在第2节中回顾了基于深度学习的正问题和反问题解决方案的近期工作。在第三节中，我们给出了我们方法的详细推导和一系列理论结果来支持所提出方法的有效性。在第4节中，我们讨论了几种可以提高实际性能的实现技术，并进行了一系列的数值实验来证明所提出方法的有效性。第五部分对本文进行了总结，并给出了一些一般性的注记。</p>
<h2 id="相关工作">相关工作</h2>
<p>在过去的几年中，使用基于深度学习的方法来解决正问题和反问题已经成为一种新的趋势。这些方法大致可以分为两类。第一类包括基于监督学习方法来近似求解给定问题的方法。这些方法通过数值模拟和实验需要大量的输入-输出对来训练所需的网络。在这一类中，深度神经网络用于从测量数据中生成近似的中间结果，用于进一步精化[34、66、69、77、81、88]，应用于改进经典数值方法在后处理阶段的求解[6、41、42、45、51、56、67、84]，或者用于近似从反问题的给定参数到其解的映射，但需要空间离散，无法应用于高维问题[2、50、63]。</p>
<p>第二类是基于问题表述直接求解正问题或反问题的无监督学习方法，而不是额外的训练数据，在实际应用中可能比第一类更有优势。例如，在[24]中，前馈神经网络用于参数化系数函数，并通过最小化性能函数进行训练。在[58]中，提出了一种名为SwitchNet的神经网络架构，通过散射体和散射场之间的映射来解决逆散射问题。文献[32]提出了一种针对2D和3D
EIT问题的深度学习方法，通过紧凑的神经网络架构来表示DtN图。前向问题中PDE对应的倒向随机微分方程(BSDE)是通过神经网络部分参数化，使得对域[13、30、43]中目标点的BSDE积分得到PDE的解。在[31]中，一个正问题的解被参数化为一个深度神经网络，它通过最小化与PDE相关的能量泛函和边值条件上的惩罚项组成的损失函数来训练。在[74]中提出了另一种无网格框架，称为物理信息神经网络(PINN)，用于使用基于PDEs的强大公式的深度神经网络来解决正问题和反问题，其中反问题部分考虑常系数函数。具体来说，PINN使用深度神经网络对给定的PDE的未知量进行参数化，这些网络通过最小化在域和边界条件采样点处违反PDE的最小二乘法形成的损失函数进行训练。PINN的一些实证研究也在[26]中进行。在[52]中也考虑了在问题域中给定数据的基于PINN的IPs的解决方案，并且在[5]中提出了使用自适应采样的配置点来精化解决方案。
在[89]中，PDE的弱形式被用作目标函数，其中PDE的解和测试函数都被参数化为深度神经网络，分别试图最小化和最大化目标函数。在[54]中，使用了类似的变分形式，其中测试函数是固定基，而不是要学习的神经网络。在[68]中，我们使用了三个神经网络，其中一个用于低保真度数据，另外两个用于高保真度数据的线性和非线性函数。具有多保真网络结构的PINN也被提出用于随机PDE情形，其中多项式混沌展开式用于表示解，即作为随机基与待学习系数函数的线性组合[18]。
在[12]中，IP的解被深度神经网络参数化，并通过最小化一个代价函数来学习，该代价函数执行IP和额外的正则化条件，其中PDE的解在训练过程中被要求。</p>
<p>最近，基于元学习的前向问题求解方法也被考虑[18、33、64]。在[33]中，我们利用小波变换的压缩形式来学习从微分算子的系数到伪微分算子(e.g.
,格林函数)的映射。在[64]中，我们引入了一个由分支网络和主干网络组成的深度算子网络。该网络将有限个位置上的输入函数(branch-net)和输出函数的位置(dry-net)进行编码，输出函数由两者的内积加上一个偏置给出。学习网络的宽度和深度参数也在[18]中使用贝叶斯优化来考虑。</p>
<p>我们的IP方法沿用了我们先前针对正问题的工作[89]，这与前面提到的现有方法在使用偏微分方程的弱形式上有所不同。<strong>弱形式是求解偏微分方程的一种强有力的方法，因为它要求更少的正则性，并允许解的必要奇异性，这在成像和异常检测等许多实际应用中都是一个重要的特征</strong>。
从理论的角度来看，<strong>我们的方法对解(作为原始网络)和测试函数(作为对抗网络)进行神经网络参数化，并以一种对抗训练的方式执行，即测试函数在不满足PDE的地方对解网络进行批判训练，解网络在这些地方进行自我修正，直到PDE在域中(几乎)处处被满足</strong>。然而，由于反问题往往是不适定的，且一般情况下比正问题更难求解，因此本文主要关注EIT中的反问题(2)。类似问题的一些实验结果也在第4节中给出。</p>
<p>本工作中的对抗训练与生成对抗网络[39]中使用的对抗训练相似，其中<strong>生成器网络旨在将通用的随机样本(如来自给定的多变量Gaussian的)映射到与训练样本具有相同分布的样本</strong>，而<strong>判别器网络则是将生成器网络产生的样本与真实样本区分开来</strong>。生成器和对抗网络作为零和博弈中的两个参与者，分别通过梯度下降和上升对目标函数进行交替更新，以达到均衡。
特别地，GAN的一个显著变体，称为Wasserstein生成式对抗网络[4]，也具有原始网络(生成器)和对抗网络(由生成分布和样本分布的Wasserstein距离决定的最优运输的对偶函数)的min-max结构作为我们的提法。然而，WGAN要求其在max问题中的对偶函数是1-Lipschitz的，这在数值上是很难实现的，并产生了一系列的后续工作来克服问题[40、70]，谱归一化生成对抗网络。相比之下，<strong>我们工作中的弱解与测试函数的结构自然地产生于PDE理论中的弱公式，它在不对对抗网络(测试函数)施加限制性约束的情况下，为PDE的IP求解提供了大量的理论证明和计算益处</strong>。</p>
<p>与许多现有的深度学习方法需要大量的演示数据(例如,系数/边界值和解对)进行训练不同，我们的方法遵循无监督的学习策略，只需要在给定的IP中制定PDE和边界条件。在[83]中，一项无监督学习研究表明，一般的卷积神经网络(CNN)自动偏向于平滑信号，并且可以在没有任何训练数据的情况下产生类似于图像去噪中一些复杂重建的结果。这种现象被称为深度图像先验(Deep
Image Prior，DIP)，在[29、46]中被进一步利用。
DIP与现有工作最显著的区别在于，我们的方法是完全无网格的，不需要任何空间离散，适用于高维问题。另一方面，在DIP及其后续工作中，重建网络被应用于离散化的2D或3D图像。此外，我们的目标是利用深度网络的表征能力来参数化连续空间中IP的解，而DIP的主要兴趣在于其有趣的自动正则化特性。</p>
<h2 id="针对反问题的弱对抗网络">针对反问题的弱对抗网络</h2>
<p>所提出的IPs弱对抗网络方法受到PDEs弱形式的启发。为了得到(1a)中偏微分方程的弱形式，我们将(1a)两边同时乘以一个任意的测试函数<span class="math inline">\(\varphi \in H_0^1(\Omega)\)</span>(在<span class="math inline">\(\Omega\)</span>中具有有界一阶弱导数和紧支撑的函数的Hilbert空间)，并在<span class="math inline">\(\Omega\)</span>上积分： <span class="math display">\[
\langle\mathcal{A}[u, \gamma], \varphi\rangle:=\int_{\Omega}
\mathcal{A}[u, \gamma](x) \varphi(x) \mathrm{d} x=0 \qquad(3)
\]</span></p>
<p><strong>弱形式(3)的主要优点之一是我们可以通过分部积分将<span class="math inline">\(\mathcal{A}[u,
\gamma]\)</span>中的某些梯度算子转移到<span class="math inline">\(\varphi\)</span>中，从而降低对<span class="math inline">\(u\)</span>(和<span class="math inline">\(\gamma\)</span>，若适用)正则性的要求</strong>。例如，在电导率逆问题(2)中，分部积分和<span class="math inline">\(\partial \Omega\)</span>上<span class="math inline">\(\varphi=0\)</span>的事实一起导致 <span class="math display">\[
\langle\mathcal{A}[u, \gamma], \varphi\rangle=\int_{\Omega}(\gamma
\nabla u \cdot \nabla \varphi-f \varphi) \mathrm{d} x=0 \qquad(4)
\]</span></p>
<p>其中<span class="math inline">\(\gamma \nabla
u\)</span>在经典意义下不一定像式(2)那样可微(在这篇文章中,我们用<span class="math inline">\(\nabla\)</span>表示关于<span class="math inline">\(x\)</span>的梯度算子,<span class="math inline">\(\nabla_\theta\)</span>表示关于<span class="math inline">\(\theta\)</span>的梯度等)。若对所有的<span class="math inline">\(\varphi \in H_0^1(\Omega)\)</span>，<span class="math inline">\((u,
\gamma)\)</span>满足边界条件(1b)和(3)，则称<span class="math inline">\((u, \gamma) \in H^1(\Omega) \times
L^2(\Omega)\)</span>为反问题(1)的弱解(或广义解)。这里<span class="math inline">\(L^2(\Omega)\)</span>是<span class="math inline">\(\Omega\)</span>上平方可积函数的Lebesgue空间，<span class="math inline">\(H^1(\Omega) \subset
L^2(\Omega)\)</span>是一阶弱导数有界的函数的Hilbert空间。注意到(1)式的任何经典(强)解也是弱解。
在这项工作中，我们寻求反问题(1)的弱解，以便我们可能能够提供问题的答案，即使它不存在经典意义上的解。</p>
<p>在文献[89]的基础上，我们考虑了(1)中PDE <span class="math inline">\(\mathcal{A}[u,
\gamma]=0\)</span>的弱形式。为了处理反问题中PDE的未知解<span class="math inline">\(u\)</span>和参数<span class="math inline">\(\gamma\)</span>，我们将<span class="math inline">\(u\)</span>和<span class="math inline">\(\gamma\)</span>都参数化为深度神经网络，并将<span class="math inline">\(\mathcal{A}[u, \gamma]: H_0^1(\Omega) \rightarrow
\mathbb{R}\)</span>看作一个线性泛函，使得<span class="math inline">\(\mathcal{A}[u,
\gamma](\varphi):=\langle\mathcal{A}[u, \gamma],
\varphi\rangle\)</span>，如式(3)所定义。我们定义由<span class="math inline">\(H_1\)</span>范数诱导的<span class="math inline">\(\mathcal{A}[u, \gamma]\)</span>范数为 <span class="math display">\[
\|\mathcal{A}[u, \gamma]\|_{o p}:=\sup _{\varphi \in H_0^1, \varphi \neq
0} \frac{\langle\mathcal{A}[u, \gamma],
\varphi\rangle}{\|\varphi\|_{H^1}} \qquad(5)
\]</span></p>
<p>其中，<span class="math inline">\(\varphi\)</span>的<span class="math inline">\(H^1\)</span>范数由<span class="math inline">\(\|\varphi\|_{H^
1(\Omega)}^2=\int_{\Omega}\left(|\varphi(x)|^2+|\nabla
\varphi(x)|^2\right) \mathrm{d} x\)</span>给出。因此，<span class="math inline">\((u, \gamma)\)</span>是(1)的弱解当且仅当<span class="math inline">\(\partial \Omega\)</span>上<span class="math inline">\(\|\mathcal{A}[u, \gamma]\|_{o p}=0\)</span>，<span class="math inline">\(\mathcal{B}[u, \gamma]=0\)</span>。当<span class="math inline">\(\|\mathcal{A}[u, \gamma]\|_{o p} \geq
0\)</span>时，我们知道方程(1)的一个弱解<span class="math inline">\((u,
\gamma)\)</span>，从而解决了方程(5)的如下观测问题： <span class="math display">\[
\underset{u, \gamma}{\operatorname{minimize}}\|\mathcal{A}[u,
\gamma]\|_{o p}^2=\underset{u, \gamma}{\operatorname{minimize}} \sup
_{\varphi \in H_0^1, \varphi \neq 0} \frac{|\langle\mathcal{A}[u,
\gamma], \varphi\rangle|^2}{\|\varphi\|_{H^1}^2} \qquad(6)
\]</span></p>
<p>其中，<span class="math inline">\((u, \gamma) \in H^1(\Omega) \times
L^2(\Omega)\)</span>，且取得最小值0。这一结果在下面的定理中进行了总结，并在附录A.1中给出了证明。</p>
<p><strong>定理1</strong> 假设<span class="math inline">\(\left(u^*,
\gamma^*\right)\)</span>满足边界条件<span class="math inline">\(\mathcal{B}\left[u^*,
\gamma^*\right]=0\)</span>，则<span class="math inline">\(\left(u^*,
\gamma^*\right)\)</span>是(1)式的弱解当且仅当<span class="math inline">\(\left\|\mathcal{A}\left[u^*,
\gamma^*\right]\right\|_{o p}=0\)</span></p>
<p><strong>定理1意味着，由于算子范数的非负性，为了找到(1)的弱解，我们可以通过求取最小的算子范数值<span class="math inline">\(\left\|\mathcal{A}\left[u^*,
\gamma^*\right]\right\|_{o p}=0\)</span>来寻找满足<span class="math inline">\(\mathcal{B}\left[u^*,\gamma^*\right]=0\)</span>且同时最小化(6)的最优解<span class="math inline">\(\left(u^*,
\gamma^*\right)\)</span>。也就是说，<span class="math inline">\(\left(u^*,
\gamma^*\right)\)</span>是问题(1)的弱解当且仅当<span class="math inline">\(\left\|\mathcal{A}\left[u^*,
\gamma^*\right]\right\|_{o p}\)</span>和<span class="math inline">\(\left\|\mathcal{B}\left[u^*,
\gamma^*\right]\right\|_{L^2(\partial
\Omega)}\)</span>都消失。因此，我们可以从下面的最小化问题中求解<span class="math inline">\(\left(u^*,
\gamma^*\right)\)</span>，等价于(1)</strong> <span class="math display">\[
\underset{u, \gamma}{\operatorname{minimize}} I(u,
\gamma)=\|\mathcal{A}[u, \gamma]\|_{o p}^2+\beta\|\mathcal{B}[u,
\gamma]\|_{L^2(\partial \Omega)}^2 \qquad(7)
\]</span></p>
<p>并且<span class="math inline">\(\beta
&gt;0\)</span>是平衡目标函数<span class="math inline">\(I(u,\gamma)\)</span>中两项的权重参数。注意到(7)式中目标函数的两项均为非负，且仅在(1)式的一个弱解<span class="math inline">\(\left(u^*,
\gamma^*\right)\)</span>处同时消失。</p>
<p>对于高维PDEs的经典数值方法，一个很有前途的替代方法是使用深度神经网络，因为它们不需要区域离散，并且是完全无网格的。深度神经网络是多个简单函数(称为层)的组合，因此它们可以逼近相当复杂的函数。考虑一个简单的多层神经网络<span class="math inline">\(u_\theta\)</span>如下： <span class="math display">\[
u_\theta(x)=w_K^{\top} l_{K-1} \circ \cdots \circ l_0(x)+b_K \qquad(8)
\]</span></p>
<p>其中，第<span class="math inline">\(k\)</span>层<span class="math inline">\(l_k: \mathbb{R}^{d_k} \rightarrow
\mathbb{R}^{d_{k+1}}\)</span>由<span class="math inline">\(l_k(z)=\sigma_k\left(W_k
z+b_k\right)\)</span>给出，权重<span class="math inline">\(W_k \in
\mathbb{R}^{d_{k+1} \times d_k}\)</span>，偏置<span class="math inline">\(b_k \in
\mathbb{R}^{d_{k+1}}\)</span>，所有层的网络参数用<span class="math inline">\(\theta\)</span>统一表示如下： <span class="math display">\[
\theta:=\left(w_K, b_K, W_{K-1}, b_{K-1}, \ldots, W_0, b_0\right)
\qquad(9)
\]</span></p>
<p>综上，本文所有向量默认为列向量。在(8)中，<span class="math inline">\(x \in \Omega\)</span>是网络的输入，<span class="math inline">\(d_0=d\)</span>是(1)的问题维数(也称为输入层的大小)，<span class="math inline">\(w_K \in \mathbb{R}^{d_K}\)</span>和<span class="math inline">\(b_K \in \mathbb{R}\)</span>是最后第<span class="math inline">\(K\)</span>层(也称为输出层)中的参数.非线性激活函数<span class="math inline">\(\sigma_k\)</span>的典型选择包括sigmoid函数<span class="math inline">\(\sigma(z)=\left(1+e^{-z}\right)^{-1}\)</span>、双曲正切(tanh)函数<span class="math inline">\(\sigma(z)=\left(e^z-e^{-z}\right)
/\left(e^z+e^{-z}\right)\)</span>和修正线性单元(ReLU)函数<span class="math inline">\(\sigma(z)=\max (0,
z)\)</span>，它们分别被应用。深度神经网络的训练是指利用可用的数据或约束优化<span class="math inline">\(\theta\)</span>的过程，使得函数<span class="math inline">\(u_\theta\)</span>可以逼近(未知)目标函数。关于深度神经网络的更多细节可参见文献[38]。</p>
<p>尽管有如式(8)的简单结构，但深度神经网络能够在紧支撑<span class="math inline">\(\bar{\Omega}\)</span>上均匀地逼近相当复杂的连续函数(以及必要时的导数)。这个重要的结果被称为万能逼近定理[47]
。由万能逼近定理保证的神经网络的表达能力表明(1)的弱解<span class="math inline">\((u,
\gamma)\)</span>)的无网格参数化是有希望的。接下来，我们对<span class="math inline">\(u\)</span>和<span class="math inline">\(\gamma\)</span>都选取足够深度的神经网络结构，如式(8)所示。数值实验中使用的具体结构，即层数<span class="math inline">\(K\)</span>和尺寸<span class="math inline">\(\left\{d_1, \ldots,
d_{K-1}\right\}\)</span>将在第4节中给出。注意到<span class="math inline">\(u\)</span>和<span class="math inline">\(\gamma\)</span>是两个独立的网络，但我们用一个字母<span class="math inline">\(\theta\)</span>来表示它们的网络参数，而不是用<span class="math inline">\(\theta_u\)</span>和<span class="math inline">\(\theta_\gamma\)</span>来简化符号。<strong>也就是说，我们将<span class="math inline">\((u, \gamma)\)</span>参数化为深度神经网络<span class="math inline">\(\left(u_\theta,
\gamma_\theta\right)\)</span>，并试图找到参数<span class="math inline">\(\theta\)</span>使得<span class="math inline">\(\left(u_\theta,
\gamma_\theta\right)\)</span>解决(7)</strong>。为此，<strong>弱式(3)中的测试函数<span class="math inline">\(\varphi\)</span>也被参数化为深度神经网络<span class="math inline">\(\varphi_\eta\)</span>，其形式类似于(8)和(9)，参数用<span class="math inline">\(\eta\)</span>表示</strong>。通过参数化的<span class="math inline">\(\left(u_\theta,
\gamma_\theta\right)\)</span>和<span class="math inline">\(\varphi_\eta\)</span>，我们遵循(3)中的内积记法并定义
<span class="math display">\[
E(\theta, \eta):=\left|\left\langle\mathcal{A}\left[u_\theta,
\gamma_\theta\right], \varphi_\eta\right\rangle\right|^2 \qquad(10)
\]</span></p>
<p>不像(平方)算子范数(5)的原始定义那样用<span class="math inline">\(\left\|\varphi_\eta\right\|_{H_1}^2\)</span>对
<span class="math inline">\(E(\theta,
\eta)\)</span>进行正规化，而是<strong>将(5)中的平方算子范数近似(上升到一个恒定的标度)为如下<span class="math inline">\(\theta\)</span>的极大值函数</strong>： <span class="math display">\[
L_{\mathrm{int}}(\theta):=\max _{|\eta|^2 \leq 2 B} E(\theta, \eta)
\qquad(11)
\]</span></p>
<p>其中<span class="math inline">\(B&gt;0\)</span>是一个限定网络参数<span class="math inline">\(\eta\)</span>大小的上界。这里<span class="math inline">\(|\eta|^2=\sum_k\left(\sum_{i j}\left[W_k\right]_{i
j}^2+\sum_i\left[b_k\right]_i^2\right),[M]_{i j} \in
\mathbb{R}\)</span>表示矩阵<span class="math inline">\(M\)</span>的<span class="math inline">\((i, j)\)</span>项， <span class="math inline">\([v]_i \in \mathbb{R}\)</span>表示向量<span class="math inline">\(v\)</span>的第<span class="math inline">\(i\)</span>个分量。值得注意的是，式(11)中对<span class="math inline">\(\eta\)</span>的<span class="math inline">\(\ell_2\)</span>-范数的界约束与WGAN
[4]中使用的权重裁剪(等价于关于<span class="math inline">\(\ell_{\infty}\)</span>-范数的界)方法类似。然而，它们服务于不同的目的：在(11)中引入约束，使得积分(如(4))是有界的(这个界的实际值可以是任意的)。在这种情况下，我们的数值实现中的蒙特卡洛近似得到的随机梯度具有有界方差，这在下面定理4的证明中是需要的。另一方面，WGAN中的权重裁剪是为了保证神经网络实现的对偶函数是1-Lipschitz函数类<span class="math inline">\(\mathcal{F}:=\{f: \Omega \rightarrow
\mathbb{R}:|f(x)-f(y)| \leq\)</span> <span class="math inline">\(|x-y|,
\forall x, y \in
\Omega\}\)</span>。正如文献[4]所指出的那样，权重裁剪是实现1-Lipschitz约束的一种简单但不合适的方法，因此有一系列的后续工作来解决这个问题，如[40、70]。</p>
<p>进一步，我们定义与边界条件(1b)相关的损失函数为 <span class="math display">\[
L_{\mathrm{bdry}}(\theta):=\left\|\mathcal{B}\left[u_\theta,
\gamma_\theta\right]\right\|_{L^2(\partial \Omega)}^2=\int_{\partial
\Omega}\left|\mathcal{B}\left[u_\theta, \gamma_\theta\right](x)\right|^2
\mathrm{~d} S(x) \qquad(12)
\]</span></p>
<p>例如，如果在(2b)中给出<span class="math inline">\((u,
\gamma)\)</span>的边界条件，且已知边界值<span class="math inline">\(\left(u_b, \gamma_b, u_n\right)\)</span>，则<span class="math inline">\(L_{\text {bdry }}(\theta)=\int_{\partial
\Omega}\left|u_\theta(x)-u_b(x)\right|^2+\left|\gamma_\theta(x)-\gamma_b(x)\right|^2+\left|\partial_{\vec{n}(x)}
u(x)-u_n(x)\right|^2 \mathrm{~d}
S(x)\)</span>。最后，定义总损失函数<span class="math inline">\(L(\theta)\)</span>，并求解如下关于其最优<span class="math inline">\(\theta^*\)</span>的最小化问题： <span class="math display">\[
\underset{\theta}{\operatorname{minimize}} L(\theta), \quad \text {
where } \quad L(\theta):=L_{\mathrm{int}}(\theta)+\beta
L_{\mathrm{bdry}}(\theta) \qquad(13)
\]</span></p>
<p>其中，我们还限制了参数<span class="math inline">\(\theta\)</span>的大小，使得对于同一个<span class="math inline">\(B\)</span>，<span class="math inline">\(|\theta|^2
\leq 2 B\)</span>，以简化记号。注意到这里<span class="math inline">\(\theta\)</span>和<span class="math inline">\(\eta\)</span>都是有限维向量，且<span class="math inline">\(L_{\text {int }}(\theta), L_{\text {bdry
}}(\theta), E(\theta, \eta) \in
\mathbb{R}_{+}\)</span>，因此可以应用数值优化算法来寻找 <span class="math inline">\(L(\theta)\)</span>的最小值。</p>
<p>求解类似于(13)的极小化问题的标准方法是<strong>投影梯度下降法</strong>，该方法执行如下迭代：
<span class="math display">\[
\theta \leftarrow \Pi\left(\theta-\tau \nabla_\theta L(\theta)\right)
\qquad(14)
\]</span></p>
<p>其中<span class="math inline">\(\Pi(\theta)=\min (\sqrt{2
B},|\theta|) \cdot(\theta /|\theta|)\)</span>是<span class="math inline">\(\theta\)</span>到以原点为圆心，半径为<span class="math inline">\(\sqrt{2 B}\)</span>的球的投影，<span class="math inline">\(\tau&gt;0\)</span>是步长.可以看出，(14)式的主要计算是在梯度<span class="math inline">\(\nabla_\theta L(\theta)=\nabla_\theta
L_{\mathrm{int}}(\theta)+\beta \nabla_\theta
L_{\mathrm{bdry}}(\theta)\)</span>上进行的。<span class="math inline">\(\nabla_\theta
L_{\mathrm{bdry}}(\theta)\)</span>的计算简单明了，如下所示。然而，损失<span class="math inline">\(L_{\text {int
}}(\theta)\)</span>被定义为一个最大化问题(11)，我们需要先将其梯度写成关于<span class="math inline">\(\theta\)</span>的函数。为此，我们有下面的引理来计算梯度<span class="math inline">\(\nabla_\theta L_{\text {int
}}(\theta)\)</span>，证明见附录A.2。</p>
<p><strong>引理2.</strong> 假设<span class="math inline">\(L_{i n
t}(\theta)\)</span>在(11)式中定义。则任意<span class="math inline">\(\theta\)</span>处的梯度<span class="math inline">\(\nabla_\theta L_{i n t}(\theta)\)</span>由<span class="math inline">\(\nabla_\theta L_{\text {int
}}(\theta)=\partial_\theta E(\theta,
\eta(\theta))\)</span>给出，其中<span class="math inline">\(\eta(\theta)\)</span>为对指定的<span class="math inline">\(\theta\)</span>求<span class="math inline">\(\max
_{|\eta|^2 \leq 2 B} E(\theta, \eta)\)</span>的解。</p>
<p><strong>注释</strong> 引理2表明，对任意给定的<span class="math inline">\(\theta\)</span>，若要得到<span class="math inline">\(\nabla_\theta L_{\text {int
}}(\theta)\)</span>，我们可以先对<span class="math inline">\(\eta\)</span>取<span class="math inline">\(E\)</span>关于<span class="math inline">\(\theta\)</span>的偏导数，然后利用<span class="math inline">\(\theta\)</span>和最大化问题(11)的解<span class="math inline">\(\eta(\theta)\)</span>求偏导数</p>
<p><span class="math inline">\(L_{\mathrm{int}}(\theta)\)</span>和<span class="math inline">\(L_{\mathrm{bdry}}(\theta)\)</span>的精确梯度需要在连续空间<span class="math inline">\(\Omega\)</span>和<span class="math inline">\(\partial
\Omega\)</span>上对深度神经网络参数化的函数进行积分，这在实际中是计算难以解决的。因此，我们采用这些积分的蒙特卡罗分析(MC)近似。为此，我们需要下面关于利用样本逼近积分的结果，其证明见附录A.3.</p>
<p><strong>引理3</strong> 假设<span class="math inline">\(\Omega \subset
\mathbb{R}^d\)</span>是有界的，<span class="math inline">\(\rho\)</span>是定义在<span class="math inline">\(\Omega\)</span>上的概率密度，使得对所有<span class="math inline">\(x \in \Omega\)</span>，<span class="math inline">\(\rho(x)&gt;0\)</span>。给定函数<span class="math inline">\(\psi \in L^2(\Omega)\)</span>，记<span class="math inline">\(\Psi=\int_{\Omega} \psi(x) \mathrm{d}
x\)</span>。设<span class="math inline">\(x^{(1)}, \ldots,
x^{(N)}\)</span>是从<span class="math inline">\(\rho\)</span>中抽取的<span class="math inline">\(N\)</span>个独立样本。考虑<span class="math inline">\(\Psi\)</span>的如下估计量<span class="math inline">\(\hat{\Psi}\)</span>：</p>
<p><span class="math display">\[
\hat{\Psi}=\frac{1}{N} \sum_{i=1}^N
\frac{\psi\left(x^{(i)}\right)}{\rho\left(x^{(i)}\right)} \qquad(15)
\]</span></p>
<p>则<span class="math inline">\(\hat{\Psi}\)</span>的一阶矩和二阶矩由下式给出.</p>
<p><span class="math display">\[
\mathbb{E}[\hat{\Psi}]=\Psi \quad \text { and } \quad
\mathbb{E}\left[\hat{\Psi}^2\right]=\frac{N-1}{N} \Psi^2+\frac{1}{N}
\int_{\Omega} \frac{\psi(x)^2}{\rho(x)} \mathrm{d} x \qquad(16)
\]</span></p>
<p>因此，<span class="math inline">\(\hat{\Psi}\)</span>的方差为<span class="math inline">\(N^{-1} \cdot\left(\int_{\Omega}\left(\psi^2 /
\rho\right) \mathrm{d} x-\left(\int_{\Omega} \psi \mathrm{d}
x\right)^2\right)\)</span>。特别地，当均匀分布<span class="math inline">\(\rho(x)=1 /|\Omega|\)</span>时，<span class="math inline">\(\hat{\Psi}=(|\Omega| / N) \cdot \sum_i
\psi\left(x^{(i)}\right)\)</span>的方差为<span class="math inline">\(N^{-1} \cdot\left(|\Omega| \int_{\Omega} \psi^2
\mathrm{~d} x-\left(\int_{\Omega} \psi \mathrm{d}
x\right)^2\right)\)</span>。</p>
<p><strong>注释</strong> 关于引理3，有几点注记：</p>
<ul>
<li><p>积分<span class="math inline">\(\Psi\)</span>的估计量<span class="math inline">\(\hat{\Psi}\)</span>是无偏的</p></li>
<li><p>上述<span class="math inline">\(\hat{\Psi}\)</span>的方差在样本配点数<span class="math inline">\(N\)</span>中以<span class="math inline">\(O(1 /
N)\)</span>的速率递减。由Hölder不等式和<span class="math inline">\(\rho\)</span>是一个概率密度，我们知道.</p></li>
</ul>
<p><span class="math display">\[
\left|\int_{\Omega} \psi \mathrm{d} x\right| \leq \int_{\Omega}|\psi|
\mathrm{d} x=\int_{\Omega} \frac{|\psi|}{\sqrt{\rho}} \sqrt{\rho}
\mathrm{d} x \leq\left(\int_{\Omega} \frac{|\psi|^2}{\rho} \mathrm{~d}
x\right)^{1 / 2}\left(\int_{\Omega} \rho \mathrm{d} x\right)^{1 /
2}=\left(\int_{\Omega} \frac{|\psi|^2}{\rho} \mathrm{~d} x\right)^{1 /
2}
\]</span></p>
<p>这也验证了<span class="math inline">\(\mathrm{V}(\hat{\Psi}) \geq
0\)</span>。更重要的是，当<span class="math inline">\(\psi\)</span>不变号且<span class="math inline">\(\rho
\propto|\psi|\)</span>时，等式成立。因此，我们可以设置<span class="math inline">\(\rho\)</span>尽可能地接近<span class="math inline">\(|\psi|\)</span>
(直到一个归一化常数)，以减小方差，但同时保证<span class="math inline">\(\rho\)</span>易于从(15)中采样和评估。这与重要性抽样的概念密切相关。</p>
<ul>
<li>引理3中的结果(15)和(16)可以很容易地推广到无界区域<span class="math inline">\(\Omega\)</span>的情形，只要<span class="math inline">\(\psi / \sqrt{\rho} \in L^2(\Omega)\)</span></li>
</ul>
<p><strong>引理3为式(14)提供了一种可行的逼近<span class="math inline">\(L(\theta)\)</span>梯度的方法</strong>。例如，要计算<span class="math inline">\(\nabla_\theta L_{\text {bdry
}}(\theta)\)</span>，可以取式(12)关于<span class="math inline">\(\theta\)</span>的梯度，在边界<span class="math inline">\(\partial \Omega\)</span>上采样<span class="math inline">\(N_b\)</span>个配置点<span class="math inline">\(\left\{x_b^{(i)}: 1 \leq i \leq
N_b\right\}\)</span> ，通过对采样点处的函数值求和近似<span class="math inline">\(\nabla_\theta
L_{\mathrm{bdry}}(\theta)\)</span>。如果我们取<span class="math inline">\(\mathcal{B}[u, \gamma]=\left(u-u_b,
\gamma-\gamma_b, \partial_{\vec{n}} u-u_n\right)\)</span>，且<span class="math inline">\(x_b^{(i)}\)</span>是一致样本，则估计变为</p>
<p><span class="math display">\[
\begin{gathered}
\nabla_\theta L_{\mathrm{bdry}}(\theta)=2 \int_{\partial
\Omega}\left(\left(u_\theta-u_b\right) \nabla_\theta
u_\theta+\left(\gamma_\theta-\gamma_b\right) \nabla_\theta
\gamma_\theta+\left(\partial_{\vec{n}} u_\theta-u_n\right) \nabla_\theta
\nabla u \cdot \vec{n}\right) \mathrm{d} S(x) \\
\approx \frac{2|\partial \Omega|}{N_b}
\sum_{i=1}^{N_b}\left(\left(u_\theta\left(x_b^{(i)}\right)-u_b\left(x_b^{(i)}\right)\right)
\nabla_\theta
u_\theta\left(x_b^{(i)}\right)+\left(\gamma_\theta\left(x_b^{(i)}\right)-\gamma_b\left(x_b^{(i)}\right)\right)
\nabla_\theta \gamma_\theta\left(x_b^{(i)}\right)\right. \\
\left.+\left(\partial_{\vec{n}}
u_\theta\left(x_b^{(i)}\right)-u_b\left(x_b^{(i)}\right)\right)
\nabla_\theta \nabla u_\theta x_b^{(i)} \cdot \vec{n} x_b^{(i)}\right)
\end{gathered} \qquad(17)
\]</span></p>
<p>类似地，我们也可以计算出<span class="math inline">\(\nabla_\theta
L_{\text {int }}(\theta)\)</span>的随机梯度。若给定<span class="math inline">\(f\)</span>，在区域<span class="math inline">\(\Omega\)</span>上取<span class="math inline">\(\mathcal{A}[u, \gamma]=\nabla \cdot(\gamma \nabla
u)-f\)</span>，且在区域<span class="math inline">\(\Omega\)</span>内均匀采样<span class="math inline">\(N_r\)</span>个配点<span class="math inline">\(\left\{x_r^{(i)}: 1 \leq i \leq
N_r\right\}\)</span> 在区域<span class="math inline">\(\Omega\)</span>内，则<span class="math inline">\(\nabla_\theta L_{\text {int
}}(\theta)\)</span>可由下式估计</p>
<p><span class="math display">\[
\begin{aligned}
\nabla_\theta L_{\mathrm{int}}(\theta) &amp; =2 I(\theta)
\int_{\Omega}\left(\nabla_\theta \gamma_\theta\left(\nabla u_\theta
\cdot \nabla
\varphi_{\eta(\theta)}\right)+\gamma_\theta\left(\nabla_\theta \nabla
u_\theta \cdot \nabla \varphi_{\eta(\theta)}\right)\right) \mathrm{d}
S(x) \\
&amp; \approx \frac{2|\Omega| \hat{I}(\theta)}{N_r}
\sum_{i=1}^{N_r}\left(\nabla_\theta
\gamma_\theta\left(x_r^{(i)}\right)\left(\nabla
u_\theta\left(x_r^{(i)}\right) \nabla
\varphi_{\eta(\theta)}\left(x_r^{(i)}\right)\right)+\gamma_\theta\left(x_r^{(i)}\right)\left(\nabla_\theta
\nabla u_\theta\left(x_r^{(i)}\right) \nabla
\varphi_{\eta(\theta)}\left(x_r^{(i)}\right)\right)\right)
\end{aligned}  \qquad(18)
\]</span></p>
<p>其中<span class="math inline">\(I(\theta)\)</span>及其估计量<span class="math inline">\(\hat{I}(\theta)\)</span>由下式给出</p>
<p><span class="math display">\[
I(\theta)=\int_{\Omega} \gamma_\theta\left(\nabla u_\theta \cdot \nabla
\varphi_{\eta(\theta)}\right) \mathrm{d} x, \quad
\hat{I}(\theta)=\frac{|\Omega|}{2} \sum_{i=1}^{N_r}
\gamma_\theta\left(x_r^{(i)}\right)\left(\nabla
u_\theta\left(x_r^{(i)}\right) \cdot \nabla
\varphi_{\eta(\theta)}\left(x_r^{(i)}\right)\right)
\]</span></p>
<p>并且根据引理2，<span class="math inline">\(\eta(\theta)\)</span>是最大化问题(11)的一个解。梯度中的所有积分都可以用类似的方式进行近似。这些近似梯度实际上是随机梯度，它是无偏的，并且由于网络参数的有界性而具有有界的方差。通过这些近似，式(14)退化为随机投影梯度下降法，通过选择合适的步长，可以保证收敛到式(13)的局部稳定点。由于(13)是有约束的，梯度映射<span class="math inline">\(\mathcal{G}(\theta):=\tau^{-1}\left[\theta-\Pi\left(\theta-\tau
\nabla_\theta L(\theta)\right)\right]\)</span>被用作<span class="math inline">\(\theta\)</span>的收敛准则[37,62,75]。值得注意的是，梯度映射的定义考虑了步长<span class="math inline">\(\tau\)</span>的归一化。 此外，在没有投影<span class="math inline">\(\Pi\)</span>的情况下，梯度映射退化为<span class="math inline">\(\mathcal{G}(\theta)=\nabla_\theta
L(\theta)\)</span>，其大小是无约束情况下局部稳定点(即, <span class="math inline">\(\left|\nabla_\theta
L(\theta)\right|=0\)</span>)的评价标准.这一结果在下面的定理中给出，并在附录A.4.中给出证明。</p>
<p><span class="math display">\[
\begin{array}{l}
   \hline \
   \textbf{算法1} \quad \text{Inverse Problem Solver by Weak Adversarial
Network(IWAN)} \\
   \hline
   \qquad \textbf{输入：}反问题(1)的区域\Omega和数据 \\
   \qquad \textbf{初始化：}\left(u_\theta, \gamma_\theta\right),
\varphi_\eta \\
   \qquad \textbf{for} \, j=1, \ldots, J \,\textbf{do} \\
   \qquad \quad \text { Sample } X_r=\left\{x_r^{(i)}: 1 \leq i \leq
N_r\right\} \subset \Omega \text { and } X_b=\left\{x_b^{(i)}: 1 \leq i
\leq N_b\right\} \subset \partial \Omega \text {. }\\
   \qquad \quad \eta \leftarrow \operatorname{SGD}\left(-\nabla_\eta
E(\theta, \eta), X_r, \eta, \tau_\eta, J_\eta\right) \text {. }\\
   \qquad \quad \theta \leftarrow
\operatorname{SGD}\left(\partial_\theta E(\theta, \eta)+\beta
\nabla_\theta L_{\mathrm{bdry}}(\theta),\left(X_r, X_b\right), \theta,
\tau_\theta, 1\right)\\
   \qquad \textbf{end for} \\
   \qquad \textbf{输出：}\left(u_\theta, \gamma_\theta\right) \\
   \hline
\end{array}
\]</span></p>
<p><strong>定理4</strong> 对于任意的<span class="math inline">\(\varepsilon&gt;0\)</span>，令<span class="math inline">\(\left\{\theta_j\right\}\)</span>是由梯度下降算法(14)生成的<span class="math inline">\(\left(u_\theta,
\gamma_\theta\right)\)</span>中的网络参数序列，在每次迭代中用样本复杂度为<span class="math inline">\(N_r,
N_b=O\left(\varepsilon^{-1}\right)\)</span>的样本均值逼近<span class="math inline">\(\nabla_\theta L(\theta)\)</span>中的积分，则<span class="math inline">\(J=O\left(\varepsilon^{-1}\right)\)</span>次迭代后<span class="math inline">\(\min _{1 \leq j \leq J}
\mathbb{E}\left[\left|\mathcal{G}\left(\theta_j\right)\right|^2\right]
\leq \varepsilon\)</span></p>
<p><strong>注释</strong> 定理4建立了(14)到问题的所谓<span class="math inline">\(\varepsilon\)</span>-解的收敛性和迭代复杂性.该结果是基于梯度映射的期望大小，这是非凸约束随机优化中的一个标准收敛准则。然而，这只能保证在期望意义下逼近一个稳定点(不一定是局部的或全局的极小点)。在理论上，我们可以将额外的全局优化技术应用到(7)中，以便找到一个具有较高计算成本的全局最优解(最好只有高概率才有可能)。然而，我们在本工作中不会对这一问题做进一步的探讨。</p>
<p>现在我们总结了我们的算法使用弱对抗网络求解IPs的步骤。为了简化表述，我们引入如下符号来表示寻找损失函数<span class="math inline">\(L(\theta)\)</span>的极小点的随机梯度下降(SGD)过程：</p>
<p><span class="math display">\[
\theta^* \leftarrow \operatorname{SGD}\left(G(\theta), X, \theta_0,
\tau, J\right) \qquad(19)
\]</span></p>
<p>也就是说，意味着输出<span class="math inline">\(\theta^*\)</span>是对<span class="math inline">\(j=0, \ldots, J-1\)</span>执行步长为<span class="math inline">\(\tau\)</span>的(投影) SGD方案，有初始<span class="math inline">\(\theta_0\)</span>之后的结果<span class="math inline">\(\theta_J\)</span>:</p>
<p><span class="math display">\[
\theta_{j+1} \leftarrow \Pi\left(\theta_j-\tau \hat{G}\left(\theta_j ;
X\right)\right) \qquad(20)
\]</span></p>
<p>这里<span class="math inline">\(X=\left\{x^{(i)}: 1 \leq i \leq
N\right\}\)</span>是<span class="math inline">\(N\)</span>个采样配置点的集合，<span class="math inline">\(G(\theta):=\nabla_\theta
L(\theta)\)</span>是损失函数<span class="math inline">\(L(\theta)\)</span>的梯度，<span class="math inline">\(\hat{G}(\theta ; X)\)</span>表示<span class="math inline">\(G(\theta)\)</span>在任意给定的<span class="math inline">\(\theta\)</span>下的随机逼近，其中积分的估计如(15)中利用采样配置点<span class="math inline">\(X\)</span>。在第一步中，我们固定<span class="math inline">\(\theta\)</span>，通过对<span class="math inline">\(J_\eta\)</span>步施加随机梯度上升来求解目标函数<span class="math inline">\(E(\theta,
\eta)\)</span>在(11)中定义的最大化问题，从而得到一个近似的最大化子<span class="math inline">\(\eta\)</span>；在第二步中，我们固定这个<span class="math inline">\(\eta\)</span>，利用梯度<span class="math inline">\(\nabla_\theta L(\theta)=\partial_\theta E(\theta,
\eta)+\beta \nabla_\theta
L_{\mathrm{bdry}}(\theta)\)</span>通过一个随机梯度下降步来更新<span class="math inline">\(\theta\)</span>
。然后进入步骤1，开始下一次迭代。因此，我们的目标函数为<span class="math inline">\(E(\theta, \eta)+\beta
L_{\mathrm{bdry}}(\theta)\)</span>，我们通过<span class="math inline">\(\min _\theta \max _\eta E(\theta, \eta)+\beta
L_{\mathrm{bdry}}(\theta)\)</span>的min-max优化来寻找最优点<span class="math inline">\(\left(\theta^*,
\eta^*\right)\)</span>。这个过程被称为使用弱对抗网络(IWAN)的反问题求解器，并在算法1中总结。数值实现中的参数值在第4节中给出</p>
<h2 id="数值实验">数值实验</h2>
<h3 id="实施细则">实施细则</h3>
<p>在这一部分中，我们讨论了关于算法1的一些实现细节和修改。首先，为了避免在固定<span class="math inline">\(\theta\)</span>的情况下求解式(11)中的内部最大化问题<span class="math inline">\(\max _\eta E(\theta,
\eta)\)</span>花费过多的时间，我们只使用少量的迭代次数<span class="math inline">\(J_\eta\)</span>来计算 <span class="math inline">\(\eta\)</span>。然后我们切换到更新<span class="math inline">\(\theta\)</span>进行一次迭代。见算法1中的两个SGD步骤。这样可以提高整体效率，避免在<span class="math inline">\(\eta\)</span>的内部最大化问题上花费过多的时间，特别是当<span class="math inline">\(\theta\)</span>还远未达到最优时。事实上，我们可以采用两个单独的测试函数<span class="math inline">\(\varphi_\eta\)</span>和<span class="math inline">\(\bar{\varphi}_\eta\)</span>
(为了记号的简洁性,我们又用同样的<span class="math inline">\(\eta\)</span>)。在每次迭代<span class="math inline">\(j\)</span>中，我们按顺序交替更新<span class="math inline">\(\left(u_\theta, \varphi_\eta, \gamma_\theta,
\bar{\varphi}_\eta\right)\)</span>，每个<span class="math inline">\(\left(u_\theta, \varphi_\eta, \gamma_\theta,
\bar{\varphi}_\eta\right)\)</span>都有一个或几个SGD步(20)。我们将为下面的实验指定这些网络的步数。</p>
<p>在第3节的推导过程中，我们要求有界的网络参数<span class="math inline">\(\theta\)</span>和<span class="math inline">\(\eta\)</span>，其中界<span class="math inline">\(B\)</span>可以任意大，以确保使用样本的积分估计量的有限方差，从而保证SGD收敛。另一种处理有界性约束的方法是在(7)的目标函数中添加<span class="math inline">\(|\theta|^2\)</span>和<span class="math inline">\(|\eta|^2\)</span>作为正则项。我们也可以使用分母为<span class="math inline">\(\|\varphi\|_2^2:=\int_{\Omega}|\varphi|^2
\mathrm{~d}
x\)</span>(用MC近似,类似于式(15))的算子范数(5)，这在我们的实现中也被采用。这种替换不会引起数值实现上的问题，因为测试函数<span class="math inline">\(\varphi_\eta\)</span>是由一个具有固定宽度/深度和有界参数的网络实现的，因此可以保证在<span class="math inline">\(H^1\)</span>中。</p>
<p>弱式(3)要求一个检验函数<span class="math inline">\(\varphi_\eta\)</span>在<span class="math inline">\(\partial
\Omega\)</span>上消失。保证这一点的一个简单技巧是，预先计算一个函数<span class="math inline">\(\varphi_0 \in C(\Omega)\)</span>，使得当<span class="math inline">\(x \in \partial \Omega\)</span>时，<span class="math inline">\(\varphi_0(x)=0\)</span>且当<span class="math inline">\(x \in \Omega\)</span>时，<span class="math inline">\(\varphi_0(x)&gt;0\)</span>(e.g.,一个到<span class="math inline">\(\partial
\Omega\)</span>的距离函数)。然后寻找一个对其任意边界无约束的参数化网络<span class="math inline">\(\varphi_\eta^{\prime}\)</span>，将测试函数<span class="math inline">\(\varphi_\eta\)</span>设置为<span class="math inline">\(\varphi_0 \varphi_\eta^{\prime}\)</span>，且在∂
<span class="math inline">\(\partial \Omega\)</span>上仍取零值。</p>
<p>我们使用TensorFlow [1]
(Python版本3.7)实现了我们的算法，这是一个先进的深度学习包，可以有效地利用GPU进行并行计算。通过TensorFlow内置的自动微分模块计算关于网络参数(<span class="math inline">\(\theta\)</span>和<span class="math inline">\(\eta\)</span>)和输入(<span class="math inline">\(x\)</span>)的梯度。在训练过程中，我们还可以用它的许多变体来代替标准的SGD优化器，如AdaGrad，RMSprop算法，Adam，Nadam等。在我们的实验中，我们使用了TensorFlow包提供的AdaGrad，在我们的大部分测试中，AdaGrad似乎提供了比其他优化器更好的性能。其他所有参数，如网络结构(层数和神经元数)、步长(也称为学习率)、迭代次数等将在第4节中指定</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/03/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%9A%84%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="宋嘉晨">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/03/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%9A%84%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">图像处理的偏微分方程方法总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-03 11:18:11" itemprop="dateCreated datePublished" datetime="2025-03-03T11:18:11+08:00">2025-03-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-05 15:39:20" itemprop="dateModified" datetime="2025-03-05T15:39:20+08:00">2025-03-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%9B%BE%E4%B9%A6%E6%80%BB%E7%BB%93/" itemprop="url" rel="index"><span itemprop="name">图书总结</span></a>
                </span>
            </span>

          
            <span id="/2025/03/03/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%9A%84%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/" class="post-meta-item leancloud_visitors" data-flag-title="图像处理的偏微分方程方法总结" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2025/03/03/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%9A%84%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/03/03/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%9A%84%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>12k</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>
<h2 id="变分法和梯度下降流">变分法和梯度下降流</h2>
<h3 id="变分原理">变分原理</h3>
<p>所希望的解往往是由最小化某一能量泛函所确定的，在一维情况下，这一泛函可能有如下形式：</p>
<p><span class="math display">\[
E(u)=\int_{x_0}^{x_1}F(x,u,u_x)\,dx  \qquad (1)
\]</span></p>
<p><span class="math inline">\(E(u)\)</span>的极值对应于变分<span class="math inline">\(\frac{\partial E}{\partial
u}=0\)</span>所对应的函数。为了求出一阶变分<span class="math inline">\(E&#39;\)</span>，考虑对最优解<span class="math inline">\(u(x)\)</span>作一微扰，得<span class="math inline">\(u(x)+v(x)\)</span>，经推导有</p>
<p><span class="math display">\[
E(u+v)=E(u)+\int_{x_0}^{x_1}[v\frac{\partial F}{\partial
u}-v\frac{d}{dx}(\frac{\partial F}{\partial u&#39;})] \, dx \qquad(2)
\]</span></p>
<p>可见，当<span class="math inline">\(E(u)\)</span>达到极值，对<span class="math inline">\(u(x)\)</span>的任一足够小微扰<span class="math inline">\(v(x),E\)</span>的值不变，故有</p>
<p><span class="math display">\[
\frac{\partial F}{\partial u}-\frac{d}{dx}(\frac{\partial F}{\partial
u&#39;})=0
\]</span></p>
<p>此式称为变分问题式(1)的Euler方程。 二维情况：</p>
<p><span class="math display">\[
E(u)=\iint_\Omega F(x,y,u,u_x,u_y)dxdy
\]</span></p>
<p>对应的Euler方程为</p>
<p><span class="math display">\[
\frac{\partial F}{\partial u}-\frac{d}{dx}(\frac{\partial F}{\partial
u_x})-\frac{d}{dy}(\frac{\partial F}{\partial u_y})=0
\]</span></p>
<p>求解能量泛函极值问题归结为求解相应的Euler方程。</p>
<h3 id="梯度下降流">梯度下降流</h3>
<p>假定我们要求的解可随时间变化，即它可以表示为<span class="math inline">\(u(\cdot,t)\)</span>，并且这种随时间的变化总是使<span class="math inline">\(E(u(\cdot,t))\)</span>减小，那么<span class="math inline">\(u(\cdot,t)\)</span>应该怎样变化才能满足这一要求？以一维问题为例，令式（2）中的微扰项<span class="math inline">\(v(\cdot)\)</span>是由<span class="math inline">\(u(\cdot,t)\)</span>从<span class="math inline">\(t\)</span>到<span class="math inline">\(t+\Delta
t\)</span>所产生的改变量，即</p>
<p><span class="math display">\[
v=\frac{\partial u}{\partial t}\Delta t
\]</span></p>
<p>式（2）就可改写为</p>
<p><span class="math display">\[
E(\cdot,t+\Delta t)=E(\cdot ,t)+\Delta t \int^{x_1}_{x_0}\frac{\partial
u}{\partial t}[\frac{\partial F}{\partial u}-\frac{d}{dx}(\frac{\partial
F}{\partial u&#39;})]\, dx
\]</span></p>
<p>于是只要令</p>
<p><span class="math display">\[
\frac{\partial u}{\partial t}=-[\frac{\partial F}{\partial
u}-\frac{d}{dx}(\frac{\partial F}{\partial
u&#39;})]=\frac{d}{dx}(\frac{\partial F}{\partial
u&#39;})-\frac{\partial F}{\partial u} \qquad(3)
\]</span></p>
<p>就可以使<span class="math inline">\(E(u(\cdot,t))\)</span>不断减小，式（3）称为变分问题式（1）所对应的梯度下降流。</p>
<p>这样一来，我们可以从某一适当选定的初始函数<span class="math inline">\(u_0\)</span>开始，根据式（3）作迭代计算，直到<span class="math inline">\(u\)</span>达到稳态解为止。这时 <span class="math display">\[
\frac{\partial u}{\partial t}=0 \Rightarrow \frac{\partial F}{\partial
u}-\frac{\mathrm{d}}{\mathrm{~d} x}\left(\frac{\partial F}{\partial
u^{\prime}}\right)=0
\]</span> 可见梯度下降流式（3）的稳态解也就是Euler方程式的解。</p>
<p>对于二维变分问题，类似推导，可得梯度下降流 <span class="math display">\[
\frac{\partial u}{\partial t}=\frac{\mathrm{d}}{\mathrm{~d}
x}\left(\frac{\partial F}{\partial
u_x}\right)+\frac{\mathrm{d}}{\mathrm{~d} y}\left(\frac{\partial
F}{\partial u_y}\right)-\frac{\partial F}{\partial u}
\]</span></p>
<p>值得特别注意的是：只有当<span class="math inline">\(E(u)\)</span>是凸性的，它有唯一极小值，从而梯度下降流可得到与初条件无关的唯一解。而当<span class="math inline">\(E(u)\)</span>非凸性时，梯度下降流可能由于选用不同的初条件<span class="math inline">\(u_0(x)\)</span>而得到不同的局部极小值而不是全局最小值。</p>
<h2 id="曲线演化问题">曲线演化问题</h2>
<h3 id="曲线几何演化的一般方程式">曲线几何演化的一般方程式</h3>
<p>曲线几何演化的一般方程式 <span class="math display">\[
\frac{\partial C(p, t)}{\partial t}=\boldsymbol{V}=\alpha(p, t)
\boldsymbol{T}+\beta(p, t) \boldsymbol{N}, \quad C(p, 0)=C_0(p) \quad(4)
\]</span> 式中<span class="math inline">\(\alpha\)</span>和<span class="math inline">\(\beta\)</span>分别为切向速率和法向速率。</p>
<p>曲线演化的一般方程式可以简化为 <span class="math display">\[
\frac{\partial C}{\partial t}=\beta \boldsymbol{N} \qquad(5)
\]</span></p>
<h2 id="水平集方法">水平集方法</h2>
<h3 id="基本概念">基本概念</h3>
<p>一条平面封闭曲线可以采用隐式表达方法，即将它定义为一个二维函数<span class="math inline">\(u(x,y)\)</span>的水平集 <span class="math display">\[
C=\lbrace (x,y),u(x,y)=c \rbrace
\]</span></p>
<p>这样，<span class="math inline">\(C\)</span>有某种变化，则我们可以将它归结为是由函数<span class="math inline">\(u(x,y)\)</span>发生了某种相应的变化所引起的。随时间变化的封闭曲线，可表达为随时间变化的二维函数<span class="math inline">\(u(x,y)\)</span>水平集，即 <span class="math display">\[
C(t):=\lbrace (x,y),u(x,y,t)=c \rbrace
\]</span></p>
<p>当曲线<span class="math inline">\(C(t)\)</span>按（4）式演化时，嵌入函数<span class="math inline">\(u(x,y,t)\)</span>应如何演化呢？对上式中的函数<span class="math inline">\(u\)</span>求全导数<span class="math inline">\(\frac{du}{dt}\)</span>，由复合函数求导的链式规则可得
<span class="math display">\[
\frac{du}{dt}=\frac{\partial u}{\partial t}+\nabla u \cdot
\frac{\partial(x,y)}{\partial t}=0
\]</span></p>
<p>考虑到式（4），<span class="math inline">\(\frac{\partial(x,y)}{\partial t}=\frac{\partial
C}{\partial t}=\boldsymbol{V}\)</span>,于是得 <span class="math display">\[
\frac{\partial u}{\partial t}=-\nabla u \cdot \boldsymbol{V}=-|\nabla u|
\frac{\nabla u}{|\nabla u|} \cdot \boldsymbol{V}=|\nabla u|
\boldsymbol{N} \cdot \boldsymbol{V}=\beta|\nabla u|  \qquad(6)
\]</span> 式中，<span class="math inline">\(\beta=\boldsymbol{v}\cdot
\boldsymbol{N}\)</span>是运动速度的法向分量。式（6）就是曲线演化水平集方法的基本方程式。</p>
<p>式（6）的推导与常数<span class="math inline">\(c\)</span>的取值无关，为了方便，常取<span class="math inline">\(c=0\)</span>，即我们关心的曲线是嵌入函数的零水平集。</p>
<p>至此，我们看到，对于封闭曲线<span class="math inline">\(C\)</span>在给定的初值<span class="math inline">\(C_0\)</span>条件下，按式（5）演化问题，等价于嵌入函数<span class="math inline">\(u(x,y)\)</span>在给定初值<span class="math inline">\(u_0(x,y)\)</span>条件下按（6）的演化，也就是说，只要在任何时刻<span class="math inline">\(t\)</span>取出<span class="math inline">\(u(x,y,t)=0\)</span>的水平集就可以确定当前曲线<span class="math inline">\(C(t)\)</span></p>
<h3 id="水平集方法的优点">水平集方法的优点</h3>
<p>第一，水平集方法的PDE是直接在固定坐标系<span class="math inline">\((x,y)\)</span>中给出的，因而是一种无参数的方法</p>
<p>第二，可采用迎风方案作数值实现，以得到粘滞解</p>
<p>第三，曲线在演化过程中可能发生拓扑变化，例如，一条封闭曲线演变为两条封闭曲线。如果采用标注质点法，则要求随时监测这种可能的变化。但是对于水平集方法而言，<span class="math inline">\(u(x,y,t)\)</span>只有数值上的变化而没有拓扑上的变化。曲线在拓扑上的任何变化，都将自动嵌入到<span class="math inline">\(u(x,y,t)\)</span>的数值变化之中。因此没有跟踪曲线拓扑变化和修改实现方案的必要。</p>
<h2 id="变分水平集方法">变分水平集方法</h2>
<h3 id="基本概念-1">基本概念</h3>
<p>在将曲线演化应用于图像处理问题时，曲线运动方程往往来自于最小化闭合曲线<span class="math inline">\(C\)</span>的某一“能量”泛函。例如，测地线活动轮廓模型就是最小化如下泛函：
<span class="math display">\[
E(C)=\oint_C g(C) \, ds \qquad(7)
\]</span></p>
<p>式中<span class="math inline">\(g(x,y)ds\)</span>是“加权弧长微元”。可以证明，式（7）的梯度下降流为
<span class="math display">\[
\frac{\partial C}{\partial t}=[g(C)\kappa-\nabla g \cdot
\boldsymbol{N}]\boldsymbol{N} \qquad (8)
\]</span> 采用前面讨论的水平集方法，则对应的关于嵌入函数的PDE为 <span class="math display">\[
\begin{aligned}
\frac{\partial u}{\partial t} &amp; =(g \kappa-\nabla g \cdot
\boldsymbol{N})|\nabla u| \\
&amp; =|\nabla u| \operatorname{div}\left(g \frac{\nabla u}{|\nabla
u|}\right)
\end{aligned} \qquad(9)
\]</span></p>
<p>针对这类由曲线的能量泛函最小化所导出的曲线演化问题，有一种新的水平集方法，称之为变分水平集方法。</p>
<p>首先，利用如下定义的特殊函数（Heaviside函数）： <span class="math display">\[
H(z)= \begin{cases}1, &amp; z \geqslant 0 \\ 0, &amp; z&lt;0\end{cases}
\]</span></p>
<p>可将关于沿<span class="math inline">\(C\)</span>的环路积分式（7）在形式上改写为面积分
<span class="math display">\[
\oint_C g(C) \mathrm{d} s=\iint_{\Omega} g(x, y)|\nabla H(u)| \mathrm{d}
x \mathrm{~d} y
\]</span></p>
<p>由于 <span class="math display">\[
\nabla H(u)=\delta(u) \nabla u, \quad \delta(z)=\frac{\mathrm{d}
H(z)}{\mathrm{d} z}
\]</span> 这样一来，式（7）便可改写为嵌入函数<span class="math inline">\(u\)</span>的泛函 <span class="math display">\[
E(u)=\iint_\Omega g(x, y) \delta(u)|\nabla u| \mathrm{d} x \mathrm{~d} y
\qquad(7&#39;)
\]</span> 利用变分法，可以得到上式的梯度下降流 <span class="math display">\[
\frac{\partial u}{\partial t}=\delta(u) \operatorname{div}\left(g
\frac{\nabla u}{|\nabla u|}\right) \qquad(10)
\]</span> 为了使它成为可实际计算的PDE，式中的<span class="math inline">\(\delta\)</span>函数需用正则化的<span class="math inline">\(\delta_{\epsilon}\)</span>作近似，即将（10）改写为
<span class="math display">\[
\frac{\partial u}{\partial t}=\delta_{\varepsilon}(u)
\operatorname{div}\left(g \frac{\nabla u}{|\nabla u|}\right) \qquad(11)
\]</span> 式中 <span class="math display">\[
\delta_{\varepsilon}(z):=\frac{\mathrm{d}}{\mathrm{~d} z} H_\epsilon(z)
\]</span> 这里，<span class="math inline">\(H_{\epsilon}(z)\)</span>称为正则化的Heaviside函数。原则上它可以是任意满足如下条件：
<span class="math display">\[
H_{\varepsilon}(z) \xrightarrow{\varepsilon \rightarrow 0} H(z)
\]</span> 的函数。</p>
<p>从表面上看，PDE式（11）与（9）似乎差别不大，只是用<span class="math inline">\(\delta_{\epsilon}(u)\)</span>取代了<span class="math inline">\(|\nabla
u|\)</span>。但是，两者在数学上有本质的差别。式（9）属于双曲型，式（11）属于抛物型，稳定性较前者高。因而在数值实现时，可用较大的时间步长，并且常常无需对嵌入函数进行重新初始化。</p>
<p>但是，这并不意味变分水平集方法就可取代水平集。因为能够采用变分水平集方法来求解曲线演化问题的前提是：该问题是来自最小化曲线<span class="math inline">\(C\)</span>的“能量”泛函<span class="math inline">\(E(u)\)</span>。这时通过引入嵌入函数<span class="math inline">\(u\)</span>和利用Heaviside函数，将<span class="math inline">\(E(C)\)</span>改造成<span class="math inline">\(E(u)\)</span>，通过变分法得到关于<span class="math inline">\(u\)</span>的PDE。而水平集方法是：先利用变分法最小化<span class="math inline">\(C\)</span>的“能量”泛函，得到关于<span class="math inline">\(C\)</span>的运动方程后，再引入嵌入函数，得到关于<span class="math inline">\(u\)</span>的PDE。问题在于，并不是所有的曲线和曲面的演化问题都是由“能量”泛函最小化而导出的。水平集方法是较变分水平集方法适用面更广的方法。</p>
<h2 id="曲线演化的线性热流">曲线演化的线性热流</h2>
<h3 id="线性几何热流">线性几何热流</h3>
<p>考虑一条简单封闭平面曲线</p>
<p><span class="math display">\[
C_0(p)=(x_0(p),y_0(p))
\]</span></p>
<p>为初始条件，按照热方程演化</p>
<p><span class="math display">\[
\frac{\partial C}{\partial t}=\frac{\partial^2 C}{\partial p^2}
\qquad(12)
\]</span></p>
<p>得到曲线族</p>
<p><span class="math display">\[
C(p,t)=(x(p,t),y(p,t)), \qquad C(p,0)=C_0(p)
\]</span></p>
<p>用Fourier方法求解得到</p>
<p><span class="math display">\[
x(p,t)=x_0(p)*g(p,t),\qquad y(p,t)=y_0(p)*g(p,t)
\\g(p,t)=\frac{1}{\sqrt{4\pi t}}\exp[\frac{-p^2}{4t}]
\]</span></p>
<p>由此可见，曲线按式(12)做线性热运动，等价于对曲线上的每一点坐标<span class="math inline">\((x,y)\)</span>同时作Gaussian滤波。并且Gaussian滤波器的标准偏离<span class="math inline">\(\sigma\)</span>与演化时间<span class="math inline">\(t\)</span>有以下对应关系：</p>
<p><span class="math display">\[
\sigma=\sqrt{2}t
\]</span></p>
<h2 id="非线性几何不变流">非线性几何不变流</h2>
<h3 id="euclidean不变流">Euclidean不变流</h3>
<p>线性热流式（12）提供了一个很好的平面曲线的多尺度表达，但它存在一个严重的不足之处，它不能保证一个简单的（不自相交的）闭合曲线在演化过程中始终保持为一条简单封闭曲线。</p>
<p>如果用曲线的Euclidean弧长<span class="math inline">\(s\)</span>取代参数<span class="math inline">\(p\)</span>，则式（12）变为</p>
<p><span class="math display">\[
\frac{\partial C}{\partial t}=\frac{\partial^2 C}{\partial s^2}
\qquad(13)
\]</span></p>
<p>考虑到<span class="math inline">\(C_s=T,C_{ss}=T_s=\kappa
N\)</span>，故式（13）可改写为</p>
<p><span class="math display">\[
\frac{\partial C}{\partial t}=\kappa N \qquad(14)
\]</span> 可见Euclidean几何不变流也就是（平均）曲率运动（MCM）方程。</p>
<p>如果令<span class="math inline">\(E(C)=\oint_C
g(C)\,ds\)</span>中的函数<span class="math inline">\(g(x,y)=1\)</span>，即能量泛函简化为 <span class="math display">\[
E(C)=\oint_C ds \qquad(15)
\]</span> 那么，最小化这一泛函的意义就是使闭合曲线<span class="math inline">\(C\)</span>的全弧长缩短。这时对应的梯度下降流式（8）中，令<span class="math inline">\(g=1,\nabla
g=0\)</span>，它将简化为式（14）。据此，也可将式（14）称为弧长缩短流。</p>
<p>可以从三个不同的出发点得到同一个曲线运动方程：
（1）集合论的形态学算子——中值滤波，在原盘结构元素半径<span class="math inline">\(r \to 0\)</span>的极限
（2）Euclidean不变几何流——以Euclidean弧长为参数的热流
（3）弧长缩短流——最小化式（15）的梯度下降流。</p>
<h3 id="仿射不变几何流">仿射不变几何流</h3>
<p>另一个有重要意义的曲线演化PDE是 <span class="math display">\[
\frac{\partial C}{\partial t}=\frac{\partial^2 C}{\partial v^2}
\qquad(16)
\]</span> 式中<span class="math inline">\(v\)</span>表示仿射弧长。有
<span class="math display">\[
C_{v v}=\kappa^{1 / 3} \boldsymbol{N}+f\left(\kappa, \kappa_v\right)
\boldsymbol{T} \\
f\left(\kappa, \kappa_v\right)=\frac{\mathrm{d}^2 s}{\mathrm{~d}
v^2}=\left(\kappa^{-1 / 3}\right)_v
\]</span>
考虑到运动速度的切线分量不影响曲线的几何形变，所以式（16）在几何上等价于
<span class="math display">\[
\frac{\partial C}{\partial t}=\kappa^{1 / 3} N \qquad(17)
\]</span>
此式称为仿射不变几何流。它将任何简单的非凸闭合形变为全凸的闭合曲线，在演化过程中，曲线逐渐平滑，不产生奇异性，也不发生自相交，因而它也生成一个尺度空间，称为仿射形态学尺度空间（AMSS）。</p>
<p>对（17）采用水平集方法，可以得到关于嵌入函数<span class="math inline">\(u\)</span>的PDE为 <span class="math display">\[
\frac{\partial u}{\partial t}=\kappa^{1 / 3}|\nabla u|=\left(u_{x x}
u_y^2-2 u_x u_y u_{x y}+u_{y y} u_x^2\right)^{1 / 3}
\]</span>
由于在此PDE中不含有分式，因而不会像MCM方程那样出现“被零除”的问题。</p>
<h2 id="测地线活动轮廓模型">测地线活动轮廓模型</h2>
<h3 id="活动轮廓模型的基本概念">活动轮廓模型的基本概念</h3>
<p>图像分割中的活动轮廓模型（active
contour）或“蛇”（snake）模型的基本思想是将图像分割问题归结为最小化一个封闭曲线<span class="math inline">\(C(p)\)</span>的“能量”泛函： <span class="math display">\[
E[C(p)]=\alpha \int_0^1\left|C_p(p)\right| \mathrm{d} p+\beta
\int_0^1\left|C_{p p}(p)\right|^2 \mathrm{~d} p-\lambda \int_0^1|\nabla
I[C(p)]| \mathrm{d} p \qquad(18)
\]</span> 式中第一项的积分是曲线的Euclidean弧长，第二项 <span class="math display">\[
\int_0^1\left|C_{p p}(p)\right|^2 \mathrm{~d}
p=\int_0^1|\kappa|^2\left(\frac{\mathrm{~d} p}{\mathrm{~d} s}\right)^2
\mathrm{~d} p
\]</span>
表示曲线“振荡”的能量。因而最小化这两项就是要求闭合曲线尽可能短并且尽可能光顺。但根据关于曲率运动演化性质的讨论可知，在短程化弧长的过程中，也将使曲线逐渐光顺，因而第二项可不必单独提出。如果图像中的对象与背景的分解处存在灰度值的较大差异，那么对象的轮廓就将形成明显的边缘，即图像的梯度模值<span class="math inline">\(|\nabla
I|\)</span>，在对象的边界将达到局部极大值。注意到第三项的符号为负，最小化<span class="math inline">\(E(C)\)</span>对应于最大化第三项，这就要求曲线<span class="math inline">\(C\)</span>尽可能落在<span class="math inline">\(|\nabla
I|\)</span>达到极大值的位置上。由此可见，“蛇”模型的基本出发点也是“基于边缘的”。由于这一模型的前提是<span class="math inline">\(C(p)\)</span>为封闭曲线，因而利用“蛇”模型分割时。将不会产生边缘断裂问题。</p>
<p>为了避免出现第三项的负号，可引入一个新的函数<span class="math inline">\(g(r),r \in
\R^+\)</span>。原则上，它可以时任何具有单调递减的非负函数，以保证<span class="math inline">\(|\nabla I|\)</span>的局部极大值对应于<span class="math inline">\(g(|\nabla
I|)\)</span>的局部极小值，从而使最大化<span class="math inline">\(\int^1_0 |\nabla I[C(p)]| \,
dp\)</span>等价于最小化<span class="math inline">\(\int g(\nabla
I[C(p)])\,
dp\)</span>。略去式（18）中的第二项，并按上述方法修改第三项，此模型便可改写成
<span class="math display">\[
E[C(p)]=\alpha_1 \int_0^1\left|C_p(p)\right| \mathrm{d} p+\alpha_2
\int_0^1 g(\nabla I[C(p)]) \mathrm{d} p \qquad(19)
\]</span></p>
<p>但是，式（19）仍然存在一个严重缺陷，即它不依赖于曲线<span class="math inline">\(C\)</span>的几何形状和位置，而且还依赖于曲线的参数<span class="math inline">\(p\)</span>。为了克服这一缺陷，提出了不含自由参数测地线活动轮廓（geodesic
active
contour，GAC）模型。GAC模型的提出是PDE方法在图像分割应用中的重大突破。</p>
<h3 id="gac模型的建立">GAC模型的建立</h3>
<p>文献[35]提出用最小化以下“能量”泛函来确定活动轮廓： <span class="math display">\[
L_R(C)=\int_0^{L(C)} g(|\nabla I[C(s)]|) \mathrm{d} s \qquad(20)
\]</span></p>
<p>式中<span class="math inline">\(L(C)\)</span>表示闭合曲线<span class="math inline">\(C\)</span>的弧长，而<span class="math inline">\(L_R
(C)\)</span>则是“加权弧长”。由于以上泛函是建立在曲线固有参数——弧长之上的，消除了经典蛇模型依赖自由参数的缺陷。</p>
<p>可以证明，最小化式（20）所对应的梯度下降流为 <span class="math display">\[
\frac{\partial C}{\partial t}=g(C) \kappa N-(\nabla g \cdot N) N
\qquad(21)
\]</span></p>
<h3 id="gac模型的行为分析">GAC模型的行为分析</h3>
<p>对（21）的行为作一定性分析。我们看到式（21）右边的前一项是平均曲率运动（MCM）乘以非负标量因子<span class="math inline">\(g(x,y)\)</span>，因而这一项与MCM的行为是一致的，即在曲率为正的局部，曲线向内部收缩，而在曲率为负的局部，曲线将向外扩张，曲线的总长度将逐渐缩短，并逐渐平滑（曲率过零点逐渐减少）。不过现在这一运动收到函数<span class="math inline">\(g(x,y)\)</span>的控制，即在平坦区，有 <span class="math display">\[
|\nabla I| \approx 0 \Rightarrow g \approx 1
\]</span> 曲线将完全按照曲率运动方程演化，但在图像边缘附近，则因为 <span class="math display">\[
|\nabla I| \gg K \Rightarrow g \approx 0
\]</span> 使第一项失去作用。</p>
<p>式（21）后一项的行为值得更仔细的考察。在图像平坦区，由于<span class="math inline">\(g \approx 1 \Rightarrow \nabla g \approx
0\)</span>，于是这一项基本失去作用。对于在图像边缘附近的情况，用图4.14来进行讨论。图4.14中的闭合曲线表示一个“对象”的边缘，假定其内部灰度值较外部低。由于梯度模值在边缘达到局部极大值，从而边缘函数<span class="math inline">\(g\)</span>达到局部极小值。在图4.14中分别用<span class="math inline">\(|\nabla I|\)</span>和<span class="math inline">\(g(|\nabla I|)\)</span>曲线表示。由于<span class="math inline">\(\nabla g\)</span>的方向总是指向<span class="math inline">\(g\)</span>增大的方向，故不论在物体的内部还是外部，<span class="math inline">\(\nabla
g\)</span>总是指向离开边缘的方向。现在假定曲线<span class="math inline">\(C(t)\)</span>已经运动到物体的边缘附近，按规定<span class="math inline">\(C(t)\)</span>的法方向<span class="math inline">\(N\)</span>总是指向曲线的内部。于是，如果当前曲线的位置是处在边界的外部，那么<span class="math inline">\(N\)</span>将与<span class="math inline">\(\nabla
g\)</span>方向相反，即<span class="math inline">\((\nabla g \cdot
N)\)</span>为负值，因而<span class="math inline">\(-(\nabla g \cdot
N)N\)</span>与<span class="math inline">\(N\)</span>相一致，可见这时第二项的作用是使<span class="math inline">\(C(t)\)</span>从边界外部。向更靠近边界的方向运动；反之，如果当前曲线的位置是处在边界的内部，那么，由于<span class="math inline">\(\nabla g\)</span>与<span class="math inline">\(N\)</span>相一致，即<span class="math inline">\(\nabla g \cdot N\)</span>取正值，故<span class="math inline">\(-(\nabla g \cdot N)N\)</span>将与<span class="math inline">\(N\)</span>方向相反，也就是说第二项的作用是使<span class="math inline">\(C(t)\)</span>从边界内部，向靠近边界的方向运动。由此可见，式（21）第二项的行为是将曲线<span class="math inline">\(C(t)\)</span>推向<span class="math inline">\(|\nabla I|\)</span>的局部极大值（也就是<span class="math inline">\(g(|\nabla
I|)\)</span>的局部极小值），并稳定平衡在<span class="math inline">\(|\nabla I|\)</span>的“屋脊”上（或者说，<span class="math inline">\(g|\nabla
I|\)</span>的“谷底”中）。但这种作用只有当<span class="math inline">\(C(t)\)</span>已经相当靠近边界，以致函数<span class="math inline">\(g(|\nabla I|)\)</span>有明显的梯度时。才能产生。
<img src="/2025/03/03/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%9A%84%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/1.png" alt="image"></p>
<p>总结以上分析可知，曲线按照GAC模型（21）演化时，将受两种“力”的支配：其一是来自于曲线自身的几何形变——曲率运动，故称为内力。不过这种“力”的强弱受到由图像<span class="math inline">\(I(x,y)\)</span>的梯度所提供的标量场<span class="math inline">\(g(x,y)\)</span>的控制。在图像边缘附近，这种“力”将变得很小以至“停止”。所以也常将边缘函数<span class="math inline">\(g(|\nabla
I|)\)</span>称之为边缘停止函数。第二种“力”来自于<span class="math inline">\(g(x,y)\)</span>的梯度<span class="math inline">\(\nabla g\)</span>，由于<span class="math inline">\(g(x,y)=g(|\nabla I(x,y)|)\)</span>，故<span class="math inline">\(\nabla y\)</span>是由图像<span class="math inline">\(I(x,y)\)</span>产生的，所以第二项的力称为外力。它能使<span class="math inline">\(C\)</span>向着图像中对象的边缘靠近，并稳定在边缘上。</p>
<p>GAC模型存在一个严重局限性，即当图像中对象由较深的凹陷边界时，GAC模型可能使<span class="math inline">\(C(t)\)</span>停止在某一<span class="math inline">\(E(C)\)</span>局部极小值状态，它并不与对象的边界相一致。图4.15是一个简单的实例，图（a）表示初始曲线，图（b）表示演化达到稳态的结果。我们看到，在对象凹陷部分，曲率<span class="math inline">\(\kappa &lt;0\)</span>。若<span class="math inline">\(C(t)\)</span>靠近这一部分，<span class="math inline">\(C(t)\)</span>的这一局部的曲率也必将是负的。式（21）前一项的“力”将是使曲线向外<span class="math inline">\((-N)\)</span>运动；另一方面，这时<span class="math inline">\(C(t)\)</span>的实际位置距离物体的边界还较远，故式（21）的后一项几乎为零。于是<span class="math inline">\(C(t)\)</span>的这部分就将停止演化，形成一段接近于直线的线段。
<img src="/2025/03/03/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%9A%84%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/2.png" alt="image"></p>
<h2 id="无边缘活动轮廓模型">无边缘活动轮廓模型</h2>
<h3 id="模型的建立">模型的建立</h3>
<p>在图像中，对象与背景的区别也可能表现为平均灰度值的明显不同。图4.23是这类图像的一个例子。由于这类图像既没有明显的边缘，也缺乏明显的纹理特征，以上讨论的GAC模型将难以实现成功的分割。
<img src="/2025/03/03/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%9A%84%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/3.png" alt="image"></p>
<p>对图4.23所示的这类图形，如果我们能找到闭合曲线<span class="math inline">\(C\)</span>，它将全部图像划分为内部区和外部区两个分部<span class="math inline">\(\Omega_1\)</span>和<span class="math inline">\(\Omega_2\)</span>，使在<span class="math inline">\(\Omega_1\)</span>内的图像部分与在<span class="math inline">\(\Omega_2\)</span>的图像的平均灰度恰好反映出对象与背景之间的灰度平均值的差别，那么这一闭合曲线就可看成是对象的轮廓。基于这一思路，T.Chan和L.Vese提出了如下“能量”泛函：
<span class="math display">\[
E\left(c_1, c_2, C\right)=\mu \oint_C \mathrm{~d} s+\lambda_1
\iint_{\Omega_1}\left(I-c_1\right)^2 \mathrm{~d} x \mathrm{~d}
y+\lambda_2 \iint_{\Omega_2}\left(I-c_2\right)^2 \mathrm{~d} x
\mathrm{~d} y \qquad(22)
\]</span></p>
<p>它有三个宗量：标量<span class="math inline">\(c_1\)</span>和<span class="math inline">\(c_2\)</span>，以及曲线<span class="math inline">\(C\)</span>。其中第一项是<span class="math inline">\(C\)</span>的全弧长，第二和第三项分别是内部区和外部区的灰度值与标量<span class="math inline">\(c_1\)</span>和<span class="math inline">\(c_2\)</span>的平方误差，也就是实际图像与假定的“分片常数”图像之间的偏离。图4.24给出了同一图像，当<span class="math inline">\(C\)</span>处在四个不同状态时，式（22）中第二项(<span class="math inline">\(F_1\)</span>)和第三项(<span class="math inline">\(F_2\)</span>)的变化情况。只有当<span class="math inline">\(C\)</span>达到“正确”位置（图4.24(d)）时，这两项才能同时达到最小值。
<img src="/2025/03/03/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%9A%84%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/4.png" alt="image"></p>
<p>式（22）称为无边缘活动轮廓模型。也可按提出者姓名称之为C-V模型。实际上，其基本思想与传统的基于区域的图像分割方法是一致的。故也可称为测地线活动区域（geodesic
active region,GAR）模型。</p>
<p>采用变分水平集方法，先在式（22）引入Heaviside函数，将它修改为关于嵌入函数<span class="math inline">\(u\)</span>的泛函，即 <span class="math display">\[
\begin{aligned}
E\left(c_1, c_2, u\right)= &amp; \mu \iint_{\Omega} \delta(u)|\nabla u|
\mathrm{d} x \mathrm{~d} y \\
&amp; +\lambda_1 \iint_{\Omega}\left(I-c_1\right)^2 H(u) \mathrm{d} x
\mathrm{~d} y+\lambda_2 \iint_{\Omega}\left(I-c_2\right)^2[1-H(u)]
\mathrm{d} x \mathrm{~d} y
\end{aligned} \qquad(23)
\]</span></p>
<p>这样，在函数<span class="math inline">\(u\)</span>固定的条件下，相对<span class="math inline">\(c_1，c_2\)</span>最小化式（23），可得 <span class="math display">\[
c_i=\frac{\iint_{\Omega_i} I \mathrm{~d} x \mathrm{~d}
y}{\iint_{\Omega_i} \mathrm{~d} x \mathrm{~d} y}, i=1,2 \qquad(24)
\]</span></p>
<p>即<span class="math inline">\(c_1\)</span>和<span class="math inline">\(c_2\)</span>分别是输入图像<span class="math inline">\(I(x,y)\)</span>在<span class="math inline">\(\Omega_1\)</span>（当前曲线的内部）和<span class="math inline">\(\Omega_2\)</span>（当前曲线的外部）的平均值。</p>
<p>在<span class="math inline">\(c_1\)</span>和<span class="math inline">\(c_2\)</span>固定的条件下，相对于<span class="math inline">\(u\)</span>最小化式（23），则可得 <span class="math display">\[
\frac{\partial u}{\partial t}=\delta_{\varepsilon}\left[\mu
\operatorname{div}\left(\frac{\nabla u}{|\nabla
u|}\right)-\lambda_1\left(I-c_1\right)^2+\lambda_2\left(I-c_2\right)^2\right]  \qquad(25)
\]</span></p>
<p>于是根据C-V模型，通过方程式（24），（25）的联立，求稳态解，便得到分割结果。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/03/Active-Contours-Without-Edges/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="宋嘉晨">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/03/Active-Contours-Without-Edges/" class="post-title-link" itemprop="url">Active_Contours_Without_Edges</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-03 08:52:42" itemprop="dateCreated datePublished" datetime="2025-03-03T08:52:42+08:00">2025-03-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-10 17:36:27" itemprop="dateModified" datetime="2025-03-10T17:36:27+08:00">2025-03-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E6%B3%9B%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文泛读</span></a>
                </span>
            </span>

          
            <span id="/2025/03/03/Active-Contours-Without-Edges/" class="post-meta-item leancloud_visitors" data-flag-title="Active_Contours_Without_Edges" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2025/03/03/Active-Contours-Without-Edges/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/03/03/Active-Contours-Without-Edges/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>12k</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="active-contours-without-edges">Active Contours Without
Edges</h1>
<p>期刊：IEEE Transactions on image processin</p>
<p>时间：2001</p>
<h2 id="摘要">摘要</h2>
<p>在本文中，我们提出了一种新的活动轮廓模型，用于检测给定图像中的对象，基于曲线演化技术，用于分割和水平集的Mumford-Shah函数。我们的模型可以检测其边界不一定由梯度定义的对象。我们最小化了能量，这可以看作是最小分区问题的一个特殊情况。在水平集公式中，问题变成了一个
“平均曲率流”
--类似演化活动等值线，它将在所需的边界上停止。然而，停止项并不依赖于图像的梯度，就像经典的主动轮廓模型那样，而是与图像的特定分割有关。我们将给出一个使用有限差分的数值算法。最后，我们将介绍各种实验结果，特别是一些基于梯度的经典蛇方法不适用的示例。此外，初始曲线可以位于图像中的任何位置，并且会自动检测内部轮廓。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/03/Active-Contours-Without-Edges/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/02/The-Perception-Distortion-Tradeoff/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="宋嘉晨">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/02/The-Perception-Distortion-Tradeoff/" class="post-title-link" itemprop="url">The_Perception-Distortion_Tradeoff</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-02 10:30:01" itemprop="dateCreated datePublished" datetime="2025-03-02T10:30:01+08:00">2025-03-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-03 12:04:52" itemprop="dateModified" datetime="2025-03-03T12:04:52+08:00">2025-03-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E6%B3%9B%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文泛读</span></a>
                </span>
            </span>

          
            <span id="/2025/03/02/The-Perception-Distortion-Tradeoff/" class="post-meta-item leancloud_visitors" data-flag-title="The_Perception-Distortion_Tradeoff" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2025/03/02/The-Perception-Distortion-Tradeoff/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/03/02/The-Perception-Distortion-Tradeoff/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.7k</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="the-perception-distortion-tradeoff感知-失真权衡">The
Perception-Distortion Tradeoff（感知-失真权衡）</h1>
<p>会议： CVPR</p>
<p>时间： 2018</p>
<h2 id="摘要">摘要</h2>
<p>图像复原算法通常是通过某种失真测度(例如：PSNR、SSIM、IFC、VIF)或通过量化感知质量的人类主观评分来评估的。在本文中，我们从数学上证明了失真和感知质量是相互矛盾的。具体来说，<strong>我们研究了从真实图像中正确判别图像复原算法输出的最佳概率</strong>。<strong>我们证明，随着平均扭曲的减小，这个概率必定增加(说明感知质量较差)</strong>。与通常的信念相反，这个结果对任何失真测度都是正确的，而不仅仅是PSNR或SSIM标准的问题。然而，正如我们在实验中所显示的那样，对于某些措施来说，(例如：VGG特征之间的距离)并不那么严重。我们还表明，生成对抗网络(Generative-adversarial-nets，GANs)为接近感知-失真界提供了一种原则性的方法。
这构成了他们在低级视觉任务中观察到的成功的理论支持。基于我们的分析，我们提出了一种新的评估图像复原方法的方法，并使用它对最近的超分辨率算法进行了广泛的比较。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/02/The-Perception-Distortion-Tradeoff/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/02/24/Unsupervised-Noise-Adaptive-Speech-Enhancement-by-Discriminator-Constrained-Optimal-Transport/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="宋嘉晨">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/24/Unsupervised-Noise-Adaptive-Speech-Enhancement-by-Discriminator-Constrained-Optimal-Transport/" class="post-title-link" itemprop="url">Unsupervised Noise Adaptive Speech Enhancement by Discriminator-Constrained Optimal Transport</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-02-24 11:26:51" itemprop="dateCreated datePublished" datetime="2025-02-24T11:26:51+08:00">2025-02-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-02-27 15:07:58" itemprop="dateModified" datetime="2025-02-27T15:07:58+08:00">2025-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E6%B3%9B%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文泛读</span></a>
                </span>
            </span>

          
            <span id="/2025/02/24/Unsupervised-Noise-Adaptive-Speech-Enhancement-by-Discriminator-Constrained-Optimal-Transport/" class="post-meta-item leancloud_visitors" data-flag-title="Unsupervised Noise Adaptive Speech Enhancement by Discriminator-Constrained Optimal Transport" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2025/02/24/Unsupervised-Noise-Adaptive-Speech-Enhancement-by-Discriminator-Constrained-Optimal-Transport/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/02/24/Unsupervised-Noise-Adaptive-Speech-Enhancement-by-Discriminator-Constrained-Optimal-Transport/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>8.9k</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="unsupervised-noise-adaptive-speech-enhancement-by-discriminator-constrained-optimal-transport判别器约束最优传输的无监督噪声自适应语音增强">Unsupervised
Noise Adaptive Speech Enhancement by Discriminator-Constrained Optimal
Transport（判别器约束最优传输的无监督噪声自适应语音增强）</h1>
<p>会议：NeurIPS</p>
<p>时间：2021</p>
<h2 id="摘要">摘要</h2>
<p>本文提出了一种新的判别器约束的最优传输网络(DOTN)，该网络执行无监督的域自适应语音增强(SE)，这是语音处理中必不可少的回归任务。<strong>DOTN旨在利用从源域获得的知识，在目标域中估计带噪语音的干净参考</strong>。训练和测试数据之间的领域转换已被报道是不同领域学习问题的障碍。尽管有丰富的文献研究无监督域适应分类，但所提出的方法，特别是在回归中，仍然是稀缺的，并且往往依赖于关于输入数据的额外信息。<strong>提出的DOTN方法将数学分析中的最优传输(OT)理论与生成对抗框架进行策略性融合，以帮助评估目标域中的连续标签</strong>。在两个SE任务上的实验结果表明，通过扩展经典的OT公式，我们提出的DOTN以一种纯无监督的方式优于先前的对抗域适应框架。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/02/24/Unsupervised-Noise-Adaptive-Speech-Enhancement-by-Discriminator-Constrained-Optimal-Transport/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/02/13/%E4%B8%A4%E4%B8%AA%E6%9B%B2%E7%BA%BF%E4%B9%8B%E9%97%B4%E7%9A%84%E8%B7%9D%E7%A6%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="宋嘉晨">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/13/%E4%B8%A4%E4%B8%AA%E6%9B%B2%E7%BA%BF%E4%B9%8B%E9%97%B4%E7%9A%84%E8%B7%9D%E7%A6%BB/" class="post-title-link" itemprop="url">两个曲线之间的距离</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-02-13 20:13:32" itemprop="dateCreated datePublished" datetime="2025-02-13T20:13:32+08:00">2025-02-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-02-14 18:48:12" itemprop="dateModified" datetime="2025-02-14T18:48:12+08:00">2025-02-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a>
                </span>
            </span>

          
            <span id="/2025/02/13/%E4%B8%A4%E4%B8%AA%E6%9B%B2%E7%BA%BF%E4%B9%8B%E9%97%B4%E7%9A%84%E8%B7%9D%E7%A6%BB/" class="post-meta-item leancloud_visitors" data-flag-title="两个曲线之间的距离" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2025/02/13/%E4%B8%A4%E4%B8%AA%E6%9B%B2%E7%BA%BF%E4%B9%8B%E9%97%B4%E7%9A%84%E8%B7%9D%E7%A6%BB/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/02/13/%E4%B8%A4%E4%B8%AA%E6%9B%B2%E7%BA%BF%E4%B9%8B%E9%97%B4%E7%9A%84%E8%B7%9D%E7%A6%BB/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.3k</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="两个曲线之间的距离">两个曲线之间的距离</h2>
<p>搜Fréchet怎么打的时候看到了Fréchet距离，感觉这两天接触的距离比较多，做下整理（说不定以后换个距离就是个创新点）</p>
<p>本篇主要介绍两个距离：<strong>Fréchet距离</strong>和<strong>Hausdorff距离</strong>。以后看到了比较两个曲线的方法再做补充（之前介绍过的两个分布之间的距离也会写篇博客整理出来）</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/02/13/%E4%B8%A4%E4%B8%AA%E6%9B%B2%E7%BA%BF%E4%B9%8B%E9%97%B4%E7%9A%84%E8%B7%9D%E7%A6%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/02/13/OPTIMAL-TRANSPORTATION-FOR-ELECTRICAL-IMPEDANCE-TOMOGRAPHY/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="宋嘉晨">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/13/OPTIMAL-TRANSPORTATION-FOR-ELECTRICAL-IMPEDANCE-TOMOGRAPHY/" class="post-title-link" itemprop="url">OPTIMAL TRANSPORTATION FOR ELECTRICAL IMPEDANCE  TOMOGRAPHY</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-02-13 19:26:47" itemprop="dateCreated datePublished" datetime="2025-02-13T19:26:47+08:00">2025-02-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-02-23 16:15:45" itemprop="dateModified" datetime="2025-02-23T16:15:45+08:00">2025-02-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文精读</span></a>
                </span>
            </span>

          
            <span id="/2025/02/13/OPTIMAL-TRANSPORTATION-FOR-ELECTRICAL-IMPEDANCE-TOMOGRAPHY/" class="post-meta-item leancloud_visitors" data-flag-title="OPTIMAL TRANSPORTATION FOR ELECTRICAL IMPEDANCE  TOMOGRAPHY" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2025/02/13/OPTIMAL-TRANSPORTATION-FOR-ELECTRICAL-IMPEDANCE-TOMOGRAPHY/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/02/13/OPTIMAL-TRANSPORTATION-FOR-ELECTRICAL-IMPEDANCE-TOMOGRAPHY/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>24k</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="optimal-transportation-for-electrical-impedance-tomography电阻抗断层成像的最优传输">OPTIMAL
TRANSPORTATION FOR ELECTRICAL IMPEDANCE
TOMOGRAPHY（电阻抗断层成像的最优传输）</h1>
<p>期刊：MATHEMATICS OF COMPUTATION</p>
<p>时间：September 2024</p>
<h2 id="摘要">摘要</h2>
<p>这项工作建立了一个用基于测地线的二次Wasserstein距离(<span class="math inline">\(W_2\)</span>)求解逆边界问题的框架。Fréchet梯度的一般形式由最优运输(
OT )理论系统推导得到。此外，基于OT在<span class="math inline">\(\mathbb{S}^1\)</span>上的新公式开发了一种快速算法来求解相应的最优运输问题。该算法的计算复杂度由传统方法的<span class="math inline">\(O(N^3)\)</span>降低到<span class="math inline">\(O(N)\)</span>。结合伴随状态方法，该框架为解决具有挑战性的电阻抗层析成像问题提供了一种新的计算方法。数值例子说明了我们方法的有效性。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/02/13/OPTIMAL-TRANSPORTATION-FOR-ELECTRICAL-IMPEDANCE-TOMOGRAPHY/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/02/11/NAS-PINN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="宋嘉晨">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/11/NAS-PINN/" class="post-title-link" itemprop="url">NAS-PINN</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-02-11 09:43:32 / 修改时间：11:45:56" itemprop="dateCreated datePublished" datetime="2025-02-11T09:43:32+08:00">2025-02-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E6%B3%9B%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文泛读</span></a>
                </span>
            </span>

          
            <span id="/2025/02/11/NAS-PINN/" class="post-meta-item leancloud_visitors" data-flag-title="NAS-PINN" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2025/02/11/NAS-PINN/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/02/11/NAS-PINN/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.9k</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="nas-pinn-neural-architecture-search-guided-physics-informed-neural-network-for-solving-pdesnas-pinn神经网络结构搜索引导的物理信息神经网络用于求解偏微分方程">NAS-PINN:
Neural architecture search-guided physics-informed neural network for
solving
PDEs(NAS-PINN：神经网络结构搜索引导的物理信息神经网络，用于求解偏微分方程)</h1>
<h2 id="摘要">摘要</h2>
<p>物理信息神经网络( PINN
)自提出以来一直是求解偏微分方程的主流框架。通过损失函数将物理信息融入到神经网络中，它可以以无监督的方式预测PDEs的解。然而，神经网络结构的设计基本依赖于先验知识和经验，这造成了很大的麻烦和较高的计算开销。因此，<strong>我们提出了一种神经结构搜索引导的方法，即NAS
- PINN，用于自动搜索求解某些PDEs的最佳神经结构</strong>。
通过将搜索空间松弛为连续空间，并利用掩码实现不同形状张量的添加，NAS -
PINN可以通过双层优化进行训练，其中内层循环优化神经网络的权重和偏置，外层循环优化网络结构参数。我们通过包括Poisson，Burgers和Advection方程在内的几个数值实验来验证NAS
-
PINN的能力。总结了求解不同PDE的有效神经网络结构的特点，可用于指导PINN中神经网络的设计。研究发现，更多的隐藏层并不一定意味着更好的性能，有时可能是有害的。
特别是对于Poisson和Advection，在PINNs中更适合采用神经元数目较多的浅层神经网络。研究还表明，对于复杂问题，具有残差连接的神经网络可以提高PINNs的性能。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/02/11/NAS-PINN/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/02/10/Lagrange%E5%AF%B9%E5%81%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="宋嘉晨">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/10/Lagrange%E5%AF%B9%E5%81%B6/" class="post-title-link" itemprop="url">Lagrange对偶（Lagrange duality）</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-02-10 19:16:52" itemprop="dateCreated datePublished" datetime="2025-02-10T19:16:52+08:00">2025-02-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-02-11 18:59:32" itemprop="dateModified" datetime="2025-02-11T18:59:32+08:00">2025-02-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a>
                </span>
            </span>

          
            <span id="/2025/02/10/Lagrange%E5%AF%B9%E5%81%B6/" class="post-meta-item leancloud_visitors" data-flag-title="Lagrange对偶（Lagrange duality）" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2025/02/10/Lagrange%E5%AF%B9%E5%81%B6/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/02/10/Lagrange%E5%AF%B9%E5%81%B6/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1.7k</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="问题背景">问题背景</h2>
<p>在一个优化问题中，原始问题通常会带有很多约束条件，这样直接求解原始问题往往是很困难的，于是考虑将原始问题转化为它的对偶问题，通过求解它的对偶问题来得到原始问题的解。<strong>对偶性</strong>（Duality）是凸优化问题的核心内容。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/02/10/Lagrange%E5%AF%B9%E5%81%B6/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="宋嘉晨"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">宋嘉晨</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">宋嘉晨</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">116k</span>
</div>

<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共116k字</span>
  <span class="post-meta-divider">|</span>
  本站总访问量<span id="busuanzi_value_site_pv"></span>次
  <span class="post-meta-divider">|</span>
  本站访客数<span id="busuanzi_value_site_uv"></span>人次
  <span class="post-meta-divider">|</span>
  本文总阅读量<span id="busuanzi_value_page_pv"></span>次
</div>

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共116k字</span>
</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'x2HNNt4kVm1AzbK4G5OMYocX-gzGzoHsz',
      appKey     : 'UZukMakW4tBBED8F52h1Hgn4',
      placeholder: "输入你的评论\n不输入昵称则为匿名",
      avatar     : '',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/clicklove.js"></script>
